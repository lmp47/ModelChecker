% Template for a Computer Science Tripos Part II project dissertation
\documentclass[12pt,a4paper,twoside,openright]{report}
\usepackage[pdfborder={0 0 0}]{hyperref}    % turns references into hyperlinks
\usepackage[margin=25mm]{geometry}  % adjusts page layout
\usepackage{graphicx}  % allows inclusion of PDF, PNG and JPG images
\usepackage{verbatim}
\usepackage{amssymb}
\usepackage{docmute}   % only needed to allow inclusion of proposal.tex
\usepackage{listings}  % for formatting code
\usepackage{float}
\usepackage[]{algorithm2e}
\floatstyle{boxed} 
\restylefloat{figure}

\raggedbottom                           % try to avoid widows and orphans
\sloppy
\clubpenalty1000%
\widowpenalty1000%

\renewcommand{\baselinestretch}{1.1}    % adjust line spacing to make
                                        % more readable

\begin{document}

\bibliographystyle{plain}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title


\pagestyle{empty}

\rightline{\LARGE \textbf{Lauren Pick}}

\vspace*{60mm}
\begin{center}
\Huge
\textbf{A Model Checker Using IC3} \\[5mm]
Computer Science Tripos -- Part II \\[5mm]
Homerton College \\[5mm]
\today  % today's date
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proforma, table of contents and list of figures

\pagestyle{plain}

\chapter*{Proforma}

{\large
\begin{tabular}{ll}
Name:                  & \bf Lauren Pick                           \\
College:               & \bf Homerton College                      \\
Project Title:         & \bf A Model Checker Using IC3             \\
Examination:        & \bf Computer Science Tripos -- Part II, 2016 \\
Word Count:            & \bf                                       \\
Project Originator:    & Lauren Pick                               \\
Supervisors:           & Dr Dominic Mulligan, Dr Ali Sezgin        \\ 
Supporting Supervisor: & Prof Alan Mycroft
\end{tabular}
}


\section*{Original Aims of the Project}

Describe the original aims of the project, i.e. summarize information from
the ``Substance and Structure'' and ``Success Criteria'' sections of the
project proposal.

\section*{Work Completed}

Describe the work completed as part of project, including extensions.

\section*{Special Difficulties}

None.
 
\newpage
\section*{Declaration}

I, Lauren Pick of Homerton College, being a candidate for Part II of the Computer
Science Tripos, hereby declare
that this dissertation and the work described in it are my own work,
unaided except as may be specified below, and that the dissertation
does not contain material that has already been used to any substantial
extent for a comparable purpose.

\bigskip
\leftline{Signed [signature]}

\medskip
\leftline{Date [date]}

\tableofcontents

%\listoffigures

%\newpage
%\section*{Acknowledgements}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% now for the chapters

\pagestyle{headings}

\chapter{Introduction}

%Provide a brief description of model checking in general.

Formal verification uses mathematics and logic to prove properties of
hardware and software systems. Formal verification techniques are
employed in several domains where the correctness of a system is
crucial. Guaranteeing that there are no errors in hardware designs before
manufacturing begins can help avoid the high costs associated with needing to
remanufacture the hardware if the design needs to be corrected.
Additionally, the ability to prove that certain kinds of errors do not
occur are important for ensuring safety in safety-critical systems such
as those in airplanes and medical devices.

% Talk about different formal verification techniques

One formal verification technique is model checking.
Given a model of the system
and a specified property, a model checker will automatically check
whether all reachable states in the system satisfy this property.

In addition to being automated, because model checkers prove
properties by considering reachable states, when a model checker
discovers that a property does not hold, the model checker has
discovered a reachable state that violates the property. A
counterexample trace can, in such cases, be provided, giving
greater insight into why the property does not hold.

A brief description of symbolic model-checking and SAT-based model-checking
follows to provide further context for this project, which focuses on
implementing the IC3 algorithm, a SAT-based model-checking algorithm.


\section{Symbolic Model Checking}

%Discuss BDD-based and SAT-based model checking techniques.
All model-checking approaches suffer from limitations on the size
of the systems they can model check in practice as a result of
the state explosion problem: the number of
states in a system can be (and often is) exponential in the
number of state variables \cite{clarke12}. 

The initial approach to the model checking problem involved explicitly
considering each reachable state in the model.
Symbolic model checking arose as a method of mitigating the effects of
the state explosion problem to some extent. By representing
states and the transition relation between them as boolean
expression, symbolic model checking allows sets of states to be
represented efficiently as boolean expressions involving state variables
as opposed to an explicit list of each individual state in the set
\cite{mcmillan92}. 

Symbolic model checking was originally invented for use with ordered
binary decision diagrams (BDDs), data structures that provide an efficient
representation of boolean formulas. A unique BDD represents each logical
formula given a particular variable ordering, and an implementation that
only stores each BDD once and uses pointers appropriately can result in
less space being used.
The efficiency of BDDs in storing boolean formulas allowed for the model
checking of systems with larger numbers of states than could be handled
by explicit-state model checking \cite{mcmillan92}.

% Transition into talking about SAT-based model checking
The efficiency of BDD representations relies on choosing an appropriate
ordering, which can be computationally expensive, and in some cases,
there is no such ordering that results in a space-efficient BDD
\cite{biere99a}.

An alternative to BDD-based symbolic model-checking techniques are SAT-based
techniques, which do not use the canonical representations of boolean
formulas as BDDs and make use of procedures for solving the boolean
satisfiability problem.
Such techniques include bounded model checking (BMC),
which proves properties by finding counterexamples of certain lengths
\cite{biere99a};
$k$-induction, which proves properties inductively \cite{sheeran00};
and the IC3 algorithm that is the focus of this project.
A brief description and comparison of these techniques follows.
% Mention FSIS?
% Mention ITP?

Many modern SAT-based model checkers are based on BMC, which begins at the
initial state of the transition system and searches for paths of length
$k$ from the initial state that violate the negated property.
If no path of length $k$ is found, BMC increments $k$ and searches again.
BMC is effective at finding counterexamples, but for some large systems,
BMC is incomplete unless it is allowed to reach the point at which $k$ is
the maximal path length.

The $k$-induction algorithm is similar to BMC in its unrolling of the
transition relation to consider paths of length $k$, but it also
incorporates induction. At each depth $k$, the algorithm asserts that the
desired property holds at each state before the final state.

% Understanding IC3

\section{The IC3 Algorithm}

%Give context for the IC3/PDR algorithm, e.g. history and comparisons
%with other SAT-based model checking algorithms such as BMC and $k$-induction.

The IC3 algorithm (also called PDR \cite{een11}) is a SAT-based model-checking
algorithm for proving the safety properties (i.e. properties that must hold
in all reachable states) of hardware.
The first implementation of the algorithm \verb,ic3, placed third in
the 2010 Hardware Model Checking Competition (HWMCC'10), a competitive event
that receives model checker and benchmark submissions from industry and
academia. Its performance at HWMCC'10 generated interest in the algorithm, and
since then, several variants of the algorithm have been developed.
%2015 paper

As in $k$-induction, properties are proved through induction:
the algorithm considers reachable sets of states $k$ steps away from the
initial state until reaching a fixed point.
% Note: find when k-induction started using counterexamples
As with later variants of $k$-induction, the IC3 algorithm also discovers
new invariants if the initial assumptions are not strong enough to prove
the desired property, but unlike $k$-induction, the safety property guides
the discovery of the invariants. As a result, the discovered invariants
are more relevant for proving the safety property \cite{bradley12}.

Furthermore, IC3 does not unroll the transition relation as $k$-induction
or other BMC-based methods do, but instead considers at most one step
of the transition relation at a time, leading to smaller,
simpler SAT queries. As a result, IC3 requires less memory than BMC-based
methods in practice \cite{bradley12}.


\section{Further Work}

%Mention other applications of the IC3 algorithm, e.g. to checking
%LTL properties and to software model checking.

%Mention IIV?

While IC3 algorithm is for model checking safety properties of hardware,
there are applications of the algorithm in model checking LTL and CTL
properties and model checking software \cite{bradley12}.

The FAIR model-checking algorithm, which model checks $\omega$-regular
properties, makes use of a safety model checker such as IC3, and IICTL,
which model-checks CTL formulas \cite{hassan12}, makes use of both a
safety model checker such as IC3 as well as a fair cycle finder such as
FAIR.

Other work generalizes IC3 to use an underlying SMT solver rather than a
SAT solver, and this generalization has been used to check control-flow
graphs of programs \cite{cimatti12}.
More recently, Johannes Birgmeier, Aaron Bradley, and Georg Weissenbacher
have introduced CTIGAR, a method of abstraction-refinement based on IC3's
counterexamples to induction rather than the counterexamples in CEGAR,
which experiments suggest is competitive with CEGAR-based techniques for
software verification \cite{birgmeier14}.

\section{Project Aims}

This project's main aim is to implement a basic form of the IC3 algorithm in
Haskell that should be able to correctly check several
small examples. Additionally, the project is meant to give me an opportunity
to learn and use Haskell, to understand formal methods and especially model
checking more deeply, and to put into practice software engineering techniques.

\chapter{Preparation}

\section{Requirements Analysis}

%Describe the requirements for the project: AIGER parser, Minisat interface,
%transition system representation, algorithm implementation.

The model checker requires a way of taking input models and also
requires a way to solve SAT queries.
I chose the AIGER format for representing the hardware models and the
MiniSat SAT solver for answering SAT queries, resulting in a need for an
AIGER parser and an interface to MiniSat in Haskell. The choice of
the AIGER format allows the model checker to be run on examples from
the Hardware Model Checking Competition, since this is the format used
to specify examples in the competitions. The choice of the MiniSat SAT
solver, which is used by Aaron Bradley's reference implementation
of IC3 that this implementation is to be compared against.

Given that the model checking algorithm deals with transition systems
(discussed later), the implementation also requires a representation of
transition systems, which should correspond to the input hardware model.
A further requirement is the implementation of the
IC3 algorithm itself.

In summary, the required components are as follows:
\begin{itemize}
\item AIGER parser
\item MiniSat interface
\item Transition system representation
\item IC3 algorithm
\end{itemize}

\section{Tools Used}

The tools used in the project are as follows:

\begin{itemize}
\item Git was used for version control, with GitHub providing backup
storage.
\item Haddock was used for documentation.
\item HUnit was used for testing.
\item Criterion was used for benchmarking.
\item Cabal was used for package/dependency management.
\item The {\tt hsc2hs} preprocessor eased writing Haskell interfaces to
C code.
\item The Aiger Utilities' parser for comparison with and as an
alternative to the one developed as part of the project.
\item The {\tt bliftoaig} and {\tt aigtoaig} tools were used to ease the specification
of models by converting from human-readable BLIF and ASCII AIG
formats to the binary AIG format.
\item The MiniSat SAT solver was used for handling SAT queries.
\end{itemize}

\section{Model Specification}
%Describe the AIGER (old and new version) and BLIF formats and
%{\tt bliftoaig} from the AIGER utilities.

%Comments?

I used both the AIGER format and Berkeley Logic Interchange Format (BLIF)
to specify the example hardware models that were not taken from the
Hardware Model Checking Competition.
The hardware models that the model checker accepts as input
are specified using the AIGER format;
however using the AIGER format to specify larger models was cumbersome,
so such models were specified using BLIF and converted to AIGER format
using the Aiger Utilities' \verb,bliftoaig, tool.

Inputs to model checker are models formatted using either the ASCII or
binary AIGER formats described below.

\subsection{AIGER}

The AIGER format provides a method of specifying hardware modeled as
And-Inverter Graphs with latch elements providing single clock-tick
delays: all circuits are modeled as a graph of nodes consisting only of
AND gates, inverters, and latches.

The AIGER format has both an ASCII and a binary version, where the ASCII
format is more flexible and human readable, and the binary version is
more compact. The Hardware Model Checking Competition's examples
use the binary format.

A new version of the AIGER format is currently under development, with
examples from HWMCC'14 using the new version. The AIGER parser implemented
as part of this project handles both the old and new versions of the AIGER
format.

\subsubsection{Old version}

All AIGER files begin with a header of the form
\begin{verbatim}
V M I L O A
\end{verbatim}
where
\begin{itemize}
\item \verb,V, can take on values \verb,aag,, specifying that the file is in the ASCII format or \verb,aig,,
specifying that the file is in the binary format.
\item \verb,M, gives the maximum index of a variable.
\item \verb,L, gives the number of latches.
\item \verb,O, gives the number of outputs.
\item \verb,A, gives the number of two-input AND gates.
\end{itemize}

Variables are represented in AIGER format with even integers greater than
1, with 0 representing the constant value {\it False} and 1
representing the constant value {\it True}.
An odd integer value $i + 1$ represents the negated value of the positive
literal represented by $i$.
In other words, a variable named $x$ is represented by $x \times 2$,
which gives the positive literal $x$, and $x \times 2 + 1$ gives the
negative literal $\neg x$.

The different components are specified after the header
in the order that their counts are given in the header.

In the ASCII version of the format, inputs are specified by giving the
index (greater than 2) that represents its corresponding variable name,
and outputs are specified similarly as single indices.
Latches initially begin with value 0 and are specified by giving the
index representing
their corresponding variable name followed by the integer that represents
the literal giving their next-state value.
AND gates are specified by giving their indices and their two inputs
literals' integer representations.

\begin{figure}[h]
\centering
\begin{verbatim}
aag 3 0 2 1 1
2 3
4 2
6
6 2 4
\end{verbatim}
\caption{
A circuit specified in the old ASCII AIGER format
}
\label{aagCircuit}
\end{figure}

For example, figure \ref{aagCircuit} specifies a circuit with
no inputs, two latches with indices $2$ and $4$ and one AND gate
$6$ that takes the outputs of the two latches as inputs and whose
output is the single output of the circuit.

In the binary version of the format, variable indices are assumed to
occur in increasing order. Since each literal must be defined, this allows
for the omission of the variable indices when defining inputs or latches.

Inputs are not explicitly listed: the input variables are inferred based on
the value of \verb,I,.
Similarly, latches are specified by only listing their next-state literals'
representations.

The binary format also assumes that AND gates occur in order of their
variable indices and additionally assumes that inputs to an AND gate will
have already been defined before that AND gate.
These assumptions allow AND gates to be represented by two differences
that tend to be small in practice:

For an AND gate specified in the old format by \verb,lhs rhs0 rhs1,,
where inputs \verb,rhs0, and \verb,rhs1, have been ordered such that
$\verb,rhs0, \geq \verb,rhs1,$, define
$$\delta_0 = \verb,lhs, - \verb,rhs0,$$
and
$$\delta_1 = \verb,lhs, - \verb,rhs1,$$

The values $\delta_i$ are then represented with the following binary
encoding, giving a more compact representation for AND gates than
the ASCII version of the format:

For 7-bit words $w_0, \ldots w_n$ with
$$\delta_i = w_0 + 2^7w_1 + \ldots + 2^{7n}w_n,$$
$\delta_i$ is represented as the sequence of $n + 1$ bytes
$b_0, \ldots, b_n$, where
\begin{itemize}
\item for $0 \leq k < n$, $b_k$ is the byte obtained by setting the most
significant bit to 1 and the rest of the bits to $w_k$, and
\item $b_n$ is the byte obtained by setting the most
significant bit to 0 and the rest of the bits to $w_n$
\end{itemize}


\subsubsection{New version}

The new AIGER format begins with a header of the form
\begin{verbatim}
V M I L O A B C J F
\end{verbatim}
where \verb,V,, \verb,M,, \verb,I,, \verb,L,, \verb,O,, \verb,A, are as
in the old format, and
\begin{itemize}
\item \verb,B, gives the number of ``bad state'' properties
\item \verb,C, gives the number of invariant constraints
\item \verb,J, gives the number of justice properties
\item \verb,F, gives the number of fairness constraints
\end{itemize}

Variables are represented in the same manner as the old format
and are specified after the header in the same order that the counts
are given in the header with the exception of AND gates, which
occur at the end of the file. Latches' initial values can also be specified
now with an additional \verb,0, or \verb,1, after the next-state literal's
index. If the initial value is omitted, the initial value is assumed to be
0 as in the old version of the format. The header can also be truncated
after giving the number of AND-gates if the remaining counts are all
zero, allowing any parser for the new AIGER format to be
backwards-compatible.

The new version of the format is otherwise
the same as the old format.

\section{The IC3 Algorithm}
%Describe how the IC3 algorithm works when trying to prove a model has a property
%$P$.
Given a hardware model (i.e. a finite-state transition system) and a
safety property $P$, IC3 aims either to prove inductively that $P$ holds
at all reachable states from the initial state or
to find a $\neg P$ state that can be reached.

\subsection{Transition Systems}
A transition system is a tuple $(i,x,I,T)$ consisting of a set of input
variables $i$, state variables $x$, next-state variables $x'$, an initial
set of states represented by the boolean expression $I(x)$ and
a transition relation represented by the boolean expression $T(i,x,x')$.

A single state of the system (or a singleton set containing that state) is
specified through the assignment
of all state variables in $x$.

\subsection{Frames}
As with other inductive approaches to model checking,
the IC3 algorithm maintains a set of $k$ frames $F_0,\ldots,F_k$, where
each frame $F_i$ is a set of clauses whose conjunction represents an
overapproximation of the set of states that reachable by the transition
system in $i$ steps
(so, for example, $F_0$ is just the initial state set $I$).

If $F_i = F_{i + 1}$ holds for any $i$ at any point, then a fixed point has
been found, and the algorithm terminates.

\subsection{Checking Properties}
%Initiation query
The initiation query $I \Rightarrow P$ is used to check that the safety
property holds in the initial state $I$.
This query is run once at the start of
the algorithm for the desired safety property. If it fails (i.e. if it
is false), then the algorithm terminates, as an error state in
which $\neg P$ holds is reachable in 0 steps. If the query succeeds,
then the algorithm proceeds.

%Consecution query
The consecution query $F_k \wedge T \Rightarrow P'$ for a frame $F_k$
is used to check whether the property $P$ necessarily holds in the next
frame.

%Recursive part of algorithm
The algorithm extends its set of frames $F_0,\ldots,F_k$ with a new frame
$F_{k + 1}$ by running the consecution query.
If the consecution query is successful, then the new frame $F_{k + 1}$
with clause $\{P\}$ can be added.
All clauses in frame $F_k$ are then propagated to $F_{k + 1}$:
For each clause $C \in F_k$, if $F_k \wedge T \Rightarrow C'$ holds, then $C'$
is added to $F_{k + 1}$.

%Describe what happens when a consecution query fails
If a consecution query $F_k \wedge T \Rightarrow P'$ fails, then that means that
there is an $F_k$ state that is a predecessor of the $\neg P'$ state,
i.e. there is an $F_k$ state $s$ and a $\neg P'$ state $v$ with $T(i,s,v')$.
The state
$s$ is a \emph{counterexample to induction} (CTI) state.

The algorithm aims to refine the approximation $F_k$ of the set of states
reachable in at least $k$ steps
by finding a clause $c$ that holds at depth $k$ such that
$F_k \wedge c \wedge T \Rightarrow P'$ holds:

Such a $c$ must be such that for the counterexample to induction $s$,
$$c \Rightarrow \neg s,$$
with an obvious choice being $c = \neg s$, which can be found easily using
a SAT solver. In practice, it is better to generalize $\neg s$ and choose
a smaller $c$,
which can allow for a set of several states to be eliminated in $F_k$
rather than just eliminating $s$. In particular, the choice of $c$ that
maximises the number of states eliminated in $F_k$ is the minimal
inductive subclause of $\neg s$ relative to frame $F_k$.

\subsection{Minimal Inductive Subclauses}
A minimal inductive subclause for a frame $F_k$ and a clause $s$ that
is inductive relative to $F_k$
(i.e. $F_0 \Rightarrow s'$ and $F_k \wedge T \wedge s \Rightarrow s'$)
is a clause $c$ whose
literals are the smallest subset of the literals in $s$ such that
$$F_k \wedge T \wedge c \Rightarrow c'$$
holds.

The minimal inductive subclause can be found by dropping each literal
in $s$ in turn and checking if the resulting clause is inductive
relative to $F_k$:

% format differently
\SetKwProg{Fn}{Function}{:}{end}
\begin{algorithm}[H]
\DontPrintSemicolon
\Fn{mic(s,k)}{
  \ForEach{literal l in s}{
    c := s $\setminus$ \{l\} \;
    \If{c is inductive relative to frame at depth k}{
      s := c \;
    }
  }
  \Return s \;
}
\end{algorithm}

Finding the minimal inductive subclause can be computationally
expensive, so it is often approximated in practice.

An improvement to the generalization provided by finding minimal
inductive subclauses in this way incorporates the use of counterexamples
to generalization.

\subsection{Counterexamples to Generalization}

Checking if a subclause $c = s / \{l\}$ of a clause $s$ is inductive
relative to a frame $F_k$, involves checking if
$F_k \wedge T \wedge c \Rightarrow c'$ holds.
If the implication does not hold, then $c$ is not inductive relative to
$F_k$. In the original method of generalization described above,
this means that $s$ cannot be generalized to $c$, and generalization
proceeds without dropping $l$.

It could be the case that the reason that the query
$F_k \wedge T \wedge c \Rightarrow c'$ is unsatisfiable because
$F_k$ is too broad an approximation, similarly to why a consecution
query at $F_k$ might fail. As with consecution queries, discovering a
new clause that can be conjoined to $F_k$ may allow the queries that
check for relative induction to succeed, and the discovery of this
clause can be directed by a counterexample extracted from the
SAT-solver after the query for $F_k \wedge T \wedge c \Rightarrow c'$.

The counterexample state in this case is called a \emph{counterexample
to generalization} (CTG), and proving the negated CTG to be true at
frame $F_k$ allows $s$ to be generalized to $c$.


\chapter{Implementation}

The implementation can be broken up into four main components: the AIGER parser, the
MiniSat interface, the hardware model representation, and the model checker.


\section{Parser}
%Discuss the implementation of the AIGER parser. In particular, mention
%the handling of both the older and newer AIGER format versions for both
%the ASCII and binary versions of the format and the representation
%of AIG models.

The parser component parses both ASCII or binary-formatted AIGER files,
assuming the new format is used (because all old format AIGER files are also
new instances of the new format). The justice properties and fairness constraints
are ignored by the parser, as they are not used by the model checker.

Both the \verb,Parser.AigerParser, module that implements the parser in Haskell and
the \verb,Parser.AigerTools, module that calls the Aiger Utilities' parser's functions
parse the AIGER file into the \verb,Model, data structure in \verb,Parser.AigModel,,
which stores the components specified in the AIGER file.

\subsection{Model}

More specifically, the \verb,Model, data structure stores the number of variables and
the number of inputs. It also stores as a list of literals the outputs, bad states,
and invariant constraints. The data structure also stores latches and AND gates as
lists of lists of literals. I discuss the representation of literals, latches, and
AND gates below.

Literals are represented by a \verb,Lit, data structure in \verb,Parser.AigModel,,
which instead of representing a positive literal $x$ as $2 \times x$ and negative
literal $\neg x$ as $2 \times x + 1$, represents positive literal $x$ as
\verb,Lit ,$x - 1$ and negative literal $\neg x$ as \verb,Neg ,$x - 1$. The subtraction
by 1 allows variable indices to start at 0 rather than 1, since starting at 1 is
unnecessary because the \verb,Lit, data struture also contains the separate
\verb,Bool, constructor for representing the values \verb,True, and \verb,False,.

Latches and AND gates are represented by three-element literal lists.
For latches, the first element gives the variable name of the latch (as a positive literal),
the second gives the next-state literal, and the final element gives the initial state
of the latch. For AND gates, the first element gives the variable name of the AND gate
(as a positive literal), and the next two elements give the literals whose values are taken
as inputs to the AND gate.

\section{Minisat Interface}
%Describe the process of implementing the Haskell bindings for Minisat
%functions, including the wrapper functions for Minisat written in C.

MiniSat serves as the SAT solver for this implementation of the IC3 algorithm.
Because the Haskell Foreign Function Interface cannot interface with C++ directly,
the interface to the MiniSat SAT solver is composed of a C wrapper for the relevant
MiniSat functions and classes and a Haskell interface to the C wrapper.

\subsection{Relevant MiniSat Functions}

To solve a SAT query, MiniSat creates an instance of a \verb,Solver, object,
which contains a set of variables, sets of clauses represented by \verb,VecLit, instances
that must be satisfied each SAT query, a model and a conflict vector.
The \verb,solveWithAssumps, function makes a SAT query that must satisfy all of the clauses
in the \verb,Solver, as well as all the literals supplied in the assumption \verb,VecLit,.

If there has been at least one query made of the \verb,Solver, object, and the query was
satisfiable, the \verb,Solver,'s \verb,model, variable points to a set of variable assignments
for that SAT query.
If there has been at least one query made of the \verb,Solver, object, and the query was
unsatisfiable, the \verb,Solver,'s \verb,conflict, variable points to a set of literals that
contains the assumed literals that caused the query to be unsatisfiable.

This model checker uses instances of \verb,SimpSolver,, a subclass of the \verb,Solver, class
that does simplification and returns full assignments.

\subsection{C Wrapper}

Much of the C wrapper is straightforward: every MiniSat class is replaced with a C type,
and every MiniSat function is replaced with a function with an \verb,extern C, function that
calls the MiniSat C++ function.
I also added an additional \verb,result, struct to allow for the results of a SAT query to
be returned from a single function call. The struct contains not only the result of the SAT
query, but also pointers to the model and conflict vector (if any) of the \verb,Solver,.
The wrapper function for \verb,solveWithAssumps, returns a pointer to a \verb,result, struct
rather than just whether or not the query was satisfiable.

\subsection{Haskell Interface}

The Haskell interface makes use of the Haskell FFI as well as the \verb,hsc2hs, preprocessor
for handling the \verb,result, struct.

Using just the Haskell FFI for calling the C functions does not provide a
sufficient abstraction for use by the rest of the model checker.
I wrote further functions to allow for a more natural interface to MiniSat,
 making use of \verb,unsafePerformIO, to have the functions return
values outside the \verb,IO, monad.

Many of the functions and datatypes in the interface are analogous to functions and structs in
the C wrapper and C++ implementation of MiniSat. For example, the \verb,Solver, datatype is an
analogue to the MiniSat \verb,Solver, object, and itself contains a pointer to an instance of
a MiniSat \verb,Solver, object. Similarly, functions such as \verb,solveWithAssumps, work
analogously to the C wrapper's \verb,solveWithAssumps,, returning a \verb,Result, that contains
whether or not the query was satisfiable and the model or conflict vector (if any).

The information kept in a \verb,Result, is taken directly from the \verb,result, returned by
the C Wrapper functions. I used the \verb,hsc2hs, preprocessor to help handle pointer offsets
when unmarshalling from the C struct. Beyond straightforward unmarshalling, some additional work
to convert from the MiniSat representation of literals to the model checkerâ€™s representation of
literals was necessary.

\section{Hardware Models}
\subsection{Representation}
\subsubsection{Literals}
The \verb,Lit, data structure in \verb,Model.Model, gives the representation for literals in
the model checker.
The \verb,Var, constructor gives positive current-state (unprimed) literals, the \verb,Neg,
constructor gives negative current-state literals, and the \verb,Var', and \verb,Neg', constructors
respectively give positive and negative next-state (primed) literals.

\subsubsection{Transition Systems and Safety Properties}
% Describe how transition systems and safety properties are represented.
The representation of transition systems and the safety property for the model checker to check
are both encompassed in the \verb,Model, data structure in \verb,Model.Model,.
The inputs $i$ and state variables $x$ in the transition system $T(i,x,I,T)$
are not distinguished, and the total count of variables is kept in \verb,vars,.
Clauses that specify the initial state $I$ are kept in \verb,initial,.
The transition relation $T$ is captured by \verb,transition,, a list of both clauses that specify
latches and clauses that specify AND gates.
The literal that gives the safety property is given by \verb,safe,.

\subsection{Construction}
% Describe how transition systems are constructed given AIG models.

The \verb,Model.Model, module contains functions to convert the \verb,Model, data
structure in \verb,Parser.AigModel, into the hardware model representation used by
the model checker.

\section{Model Checking}

I have implemented several versions of the recursive IC3 algorithm:
the most basic version (\emph{Basic}), a version that
improves upon the most basic version by discovering smaller CTIs (\emph{BetterCTI}),
and a version that improves upon the version with improved CTIs by considering subsumed clauses
(\emph{BetterPropagation}).

I have also implemented a variation of IC3 that uses priority queues (\emph{PriorityQueue}) and a
variation that uses CTGs to improve generalization (\emph{CTG}).

\begin{tabular}{l | p{3.5em} | p{3em} | p{4.5em} | p{5em} | p{6em}}
& Priority Queue & Smaller CTIs & Subsumed Clauses & Basic Generalization & Generalization with CTGs\\
\hline
\emph{Basic} & & & \checkmark & \\
\emph{BetterCTI} & & \checkmark & & \checkmark & \\
\emph{BetterPropagation} & & \checkmark & \checkmark & \checkmark &\\
\emph{PriorityQueue} & \checkmark & \checkmark & \checkmark & & \\
\emph{CTG} & & \checkmark & \checkmark & & \checkmark
\end{tabular}

\subsection{Overall structure}

All versions of the model checker begin with a call to the \verb,prove, function,
passing a \verb,Model, and the \verb,Lit, that is the safety property. The
\verb,prove, function first creates the frame for the initial state and makes an
initiation query. If the query is unsuccessful and returns \verb,False,,
then \verb,prove, can just return \verb,False,, since the safety property
does not hold in the initial state. Then \verb,prove, calls \verb,prove',, which
has different implementations based on whether the version is recursive or not.

\subsubsection{Recursive}
In the general structure for the recursive implementations of the model checker,
\verb,prove', takes as arguments the \verb,Model, for the hardware, the
\verb,Lit, that gives the safety property, the frontier \verb,Frame, 
(i.e. the \verb,Frame, that approximates the reachable set at the greatest
depth considered so far), and the rest of the \verb,Frame,s in a list ordered by
increasing depth.

The \verb,prove', function makes a consecution query for the safety property and frontier
frame \verb,frame,. If the consecution query returns \verb,True,, then \verb,prove',
creates a new frame and calls \verb,pushFrame, which uses the \verb,push, function to
push as many clauses as possible from \verb,frame, to the new frame. If \verb,push,
indicates that a fixed point has been reached, then \verb,pushFrame, returns \verb,True,,
but otherwise \verb,pushFrame, calls \verb,prove', recursively with the new frontier
frame added to the list of frames.

If the consecution query returns \verb,False,, then \verb,prove', calls \verb,nextCTI,
to find a (possibly incomplete, depending on the implementation version)
assignment whose current-state literals give a CTI cube.
The CTI is extracted from the result of \verb,nextCTI, and passed along to \verb,proveNegCTI,
along with the frontier frame, the rest of the frames, and the safety property.

The function \verb,proveNegCTI, attempts to show that the CTI
$s$ is unreachable at the current depth by showing that $\neg s$ holds in the current frame.
The function checks first that $I \wedge \neg s \wedge s'$ is unsatisfiable
(i.e. to check that $I \wedge \neg s \Rightarrow \neg s'$ and therefore that $\neg s$ is
inductive relative to $I$). Then \verb,pushNegCTI, finds the deepest frame (the frame
$F_k$ with the largest $k$) that comes before the frame that contains the counterexample to
induction state relative to which $\neg s$ is inductive and adds the clause
$\neg s$ to all frames up to that depth.

If this deepest frame $F_{k - 1}$ is the frame just before the frame that contains the
CTI, then since $\neg s$ is inductive relative to $F_{k - 1}$, $\neg s$ can also be added
to $F_k$, establishing that $\neg s$ is not reachable in $k$ steps. The \verb,pushNegCTI,
function in this case yields a triple \verb:(Nothing, acc', f'):, where \verb,acc', gives
a list containing the representation of frames $F_0, \ldots, F_{k - 1}$ after having $\neg s$
conjoined to them, and \verb,f', contains the representation of frame $F_k$ after having
$\neg s$ conjoined to it. The function \verb,proveNegCTI, then checks again if the safety
property is inductive relative to the updated $F_k$. If so, then \verb,proveNegCTI, has
successfully proven enough CTIs are unreachable at depth $k$. Otherwise, \verb,proveNegCTI,
calls \verb,nextCTI, to extract the next CTI to prove unreachable at depth $k$ and calls
itself recursively with this newly-discovered CTI.

If the deepest frame $F_{k - 1}$ to which $\neg s$ is relatively inductive is not the frame just before
the CTI-containing frame, then \verb,proveNegCTI, uses \verb,nextCTI, to find a new CTI $z$
that is a counterexample for the property $\neg s$ being relatively inductive to $F_k$. It then
calls itself recursively with this new CTI to prove, and the frames up to $F_{k - 1}$ rather than
$F_k$. After updating frames $F_0, \ldots F_{k - 1}$ to prove that $\neg z$ holds at $F_{k - 1}$,
the call to \verb,negCTI, to prove $\neg s$ is repeated using the updated frames $F_0, \ldots, F_{k - 1}$.

If any call to \verb,proveNegCTI, ever reaches the point where the only frame it is called with is
$F_0$, then \verb,proveNegCTI, has failed to prove a property necessary to show that the error
state is unreachable, and the model checker can then give the result that the safety property
does not hold.

When \verb,proveNegCTI, successfully proves a negated CTI unreachable, \verb,prove', then propagates
clauses through all frames from the inital frame $F_0$ to the frontier frame and checks for a fixed
point. If a fixed point has been found, then the safety property holds at all reachable states and the
model checker can return \verb,True,. Otherwise, \verb,prove', calls itself recursively to prove
the safety property at the same depth, but with the updated frames (with negated CTIs conjoined
to them).

\subsubsection{Priority queues}

The priority queue implementation keeps track of what to prove next by using a priority queue of proof
obligations instead of through recursive calls that explicitly specify which property to prove at
which depth. A proof obligation is a pair $(s,i)$ of a state $s$ that is either a set of bad states
or a counterexample to induction and a depth $i$. When the model checker encounters a proof obligation
$(s,i)$ as the highest-priority element of the queue, it must prove $\neg s$ at depth $i$ to fulfill
$(s, i)$.
The presence of proof obligation $(s,i)$ on the priority queue also indicates that for all values $j$
with $0 \leq j < i$, $(s, j)$ has already been fulfilled.

The implementation represents proof obligations $(s,i)$ using the \verb,Obligation, type, which
is a triple \verb.(Int, Int, Clause). of the depth $i$, a rank for deciding the ordering of
proof obligations at the same depth within the priority queue, and the clause $\neg s$.

In the \emph{PriorityQueue} implementation, \verb,prove', also takes a \verb,Model, as a parameter
but otherwise takes a \verb,MinQueue, (the minimal element has the highest
priority) of \verb,Obligation,s containing the priority queue with only \verb,Obligation,
\verb.(1, 0, [prop]). in it, and the initial frame. The function \verb,prove', then invokes \verb,proveObligations,,
the main function for the \emph{PriorityQueue} implementation.

The \verb,proveObligations, function removes the minimum (i.e. highest-priority) \verb,Obligation, 
representing $(s,i)$ from the priority queue and makes the consecution query
$F_{i - 1} \wedge T \Rightarrow \neg s$. If the consecution query returns \verb,True,,
then \verb,proveObligations, invokes \verb,pushFrame,, which works the same as in the recursive version,
except that the recursive call to \verb,prove', is replaced with a recursive call to \verb,proveObligations,
with an updated priority queue that has proof obligation $(s, i + 1)$.

If the consecution query instead returns \verb,False,, then the negated CTI $\neg s$ is found by
negating the extracted current-state literals taken from the value given by an invocation of \verb,nextCTI,.
The \verb,proveObligations, function checks that $\neg s$ does not hold in the initial state, adds $\neg s$
to frame $F_0$, and then invokes the \verb,propagate, function to propagate clauses until one of the following
occurs:
\begin{itemize}
\item The depth $i$ in the proof obligation has been reached
\item The clause $\neg s$ can no longer be pushed
\item A fixed point has been reached.
\end{itemize}
In the first case, \verb,proveObligations, enqueues obligation $(s,i)$ with a rank that gives it a priority
such that it occurs after all other proof obligations at depth $i$ and calls itself recursively.
In the second case, \verb,propagate, gives the greatest $j$ such that $\neg s$ has been shown to hold at
$j$-steps from the initial state (i.e. $\neg s$ is inductive relative to $F_{j - 1}$. Then \verb,proveObligations,
enqueues obligation $(s,j)$ with a rank that gives it a priority such that it occurs after all other
proof obligations at depth $j$ and calls itself recursively.
In the third case, \verb,proveObligations, returns a value containing \verb,True,, since the safety property
has been proven to hold at all reachable states.

\subsection{Frames}
The \verb,Frame, data structure represents frames in the IC3 algorithm.
Along with the set of clauses (represented by a list of literals), a \verb,Frame, also includes
a \verb,Solver,, which contains at least all the clauses in the frame's set of clauses. The
\verb,Solver, may also contain the \verb,transition, clauses for the hardware model.

\subsection{Initiation}
%Describe how the step involving the initiation query is implemented.

The initiation query $I \Rightarrow P$ is an implication, but a MiniSat \verb,Solver, can only
solve queries given in conjunctive normal form (CNF), where each disjunct is one of the clauses passed
to the solver (assumptions passed to the solver can be taken as a set of single-literal clauses
that are also part of the conjunction). As a result, the representation for the query
$I \Rightarrow P$ for a frame $I$ and a clause $P$ makes use of the logical equivalence between
$I \Rightarrow P$ and $\neg (\neg P \wedge I)$.

Using the fact that the formula $\neg (\neg P \wedge I)$ is true iff $\neg P \wedge I$ is unsatisfiable,
and deMorgan's laws gives the following implementation of the initiation query:

\begin{verbatim}
initiation :: Frame -> Clause -> Bool
initiation = not (satisfiable (solveWithAssumps (solver f) (map neg prop)))
\end{verbatim}

\subsection{Consecution}
%Describe how the step involving the consecution query is implemented.

Similarly to how the implication in the initiation query is converted to an equivalent logical
expression that renders a CNF query to a MiniSat \verb,Solver, to determine the satisfiability
of the query, the consecution query's implementation uses the logical equivalence of
$F_k \wedge T \Rightarrow P'$ and $\neg (\neg P' \wedge F_k \wedge T)$. Again, along with deMorgan's
laws, this yields the implementation of the consecution query (where it is assumed that the
\verb,Frame,'s \verb,Solver, contains the \verb,transition, clauses of the \verb,Model,.

\begin{lstlisting}
\end{lstlisting}

\subsection{Counterexamples to Induction}
%Describe how the implementation discovers counterexamples
%to induction and proves them unreachable.

When the consecution query $F_k \wedge T \Rightarrow P$
in \verb,prove', fails, then a call to the function \verb,nextCTI,
gives a cube (a conjunction of literals) whose current-state literals
give relevant CTI for the query. After, in the recursive version,
\verb,proveNegCTI, attempts to prove that the CTI cannot be reached
(which may involve further calls to \verb,nextCTI,), and in
the \emph{PriorityQueue} version, \verb,proveObligations, enqueues
a proof obligation for proving the negated CTI.

\subsubsection{Basic}
In the \emph{Basic} implementation of the IC3 algorithm, \verb,negCTI, asks for a model
(i.e. the set of true literals) for the satisfiable query $\neg P' \wedge F_k \wedge T$.
The current-state literals are then extracted from the model in the function that
called \verb,negCTI,.

\subsubsection{Smaller Counterexamples to Induction}
In the other implementations of the algorithm, \verb,negCTI, again asks for a model $m$
for the satisfiable query $\neg P' \wedge F_k \wedge T$. The only literals in $m$ that
must necessarily be included in the CTI are those current-state literals that result in
the unsatisfiability of $m \wedge P' \wedge T$. That is, the current-state literals of any
subcube $q$ of $m$ for which $q \wedge P' \wedge T$ holds is also a valid CTI.
The conflict vector resulting from querying the SAT solver with $P' \wedge T$ and assumption
cube $m$ contains such a $q$ that has only literals relevant to the conflict. This $q$ is
then returned to the calling function, which, as in the \emph{Basic} implementation, extracts
the current-state literals from $q$.


\subsection{Propagation}

\subsubsection{Basic}
The most basic implementation's \verb,push, function, when invoked as \verb,push f model f', tries
to push all clauses in \verb,Frame, \verb,f, that are not in \verb,Frame, \verb,f', to \verb,f', and
results in a pair containing a \verb,Bool, indicating whether a fixed point has been reached
(i.e., all clauses could be pushed) and a \verb,Frame, with all the clauses in \verb,f', and all
the clauses in \verb,f, that could be pushed to \verb,f',.
For each clause in \verb,f, that is not in \verb,f', the \verb,consecution, function is called to
see if the clause is inductive relative to the frame represented by \verb,f,. If it is, then
the clause can be conjoined to the frame represented by \verb,f',, and if it is not, then the
function must have \verb,False, as the first element in the pair it returns.

\subsubsection{Subsumed clauses}
The basic implementation's \verb,push, function avoids unnecessary consecution queries by only
considering clauses in \verb,f, that are not in \verb,f',. Further consecution queries may be
eliminated by considering the clauses in \verb,f, that are subsumed by other clauses.

A clause $c$ subsumes a clause $c'$ if the literals in $c$ are a subset of the literals in $c'$.
In this case, $c \Rightarrow c'$ holds, so $c'$ can be removed from the set of clauses. By
removing all subsumed clauses $c'$ from a frame before trying to push clauses, the model
checker can avoid making the consecution queries that arise from attempts to push those clauses.

The versions of \verb,push, that consider subsumed clauses include a call to the function
\verb,removeSubsumed, when acquiring the list of clauses to attempt to push.
The \verb,removeSubsumed, function takes a list of clauses and removes all clauses in the list
that are subsumed by other clauses in the list. The \verb,push, function replaces the frame
\verb,f, with a version of \verb,f, with all the subsumed clauses in the frame removed for
the rest of the function and proceeds as the basic implementation's \verb,push, function does,
returning a triple containing the updated \verb,f, along with the fixed-point \verb,Bool,
and updates \verb,Frame, \verb,f',.

\subsection{Generalization}
While the algorithm describes generalization as involving finding the minimal inductive subclause (MIC),
finding the MIC for a clause is in practice inefficient, and all implemented versions of generalization
\verb,inductiveGeneralization, involve approximating the MIC.

\subsubsection{Simple}
The simplest approximation for a MIC involves attempting to drop each literal in turn and checking
that the resulting clause $c$ results in the truth of formulas $I \Rightarrow c$ and
$F_k \wedge c \wedge T \Rightarrow c'$ that the original clause did. If the resulting clause
does result in satisfiable results for both the queries, then the literal can be successfully dropped,
but if not, the literal is added to a list \verb,needed, of necessary literals.
After a parameterizable number of failed attempts at dropping a literal from the clause or after
having attempted dropping all the literals, the
\verb,inductiveGeneralization, function returns the clause resulting from appending the remaining
literals in the clause (i.e. the literals that \verb,inductiveGeneralization, has not tried to drop)
with the literals in \verb,needed,.

\subsubsection{Minimal Inductive Subclauses and Counterexamples to Generalization}
The more elaborate implementation of generalization implements the full
(but limited in number of attempts) MIC algorithm implementation with the ability to deal with CTGs.

When attempting to drop a literal $l$ from clause $c$, the \verb,down, function is called on the clause
$c \setminus l$ with a list of past frames (which is all the frames except the deepest on the inital call
to \verb,down,), a list of current and future frames (which contains only the deepest frame on initial call
to \verb,down,), and a limit on the recursion depth \verb,r,.

The \verb,down, function checks, as in the simple approximation for MIC, for the satisfiability of
$I \Rightarrow c$ and $F_k \wedge c \wedge T \Rightarrow c'$. The difference is that \verb,down,
does not immediately give a value if $I \Rightarrow c$ is true and $F_k \wedge c \wedge T \Rightarrow c'$ is
not; in this case, the negated cTG \verb,negCTG, is acquired by taking and negating the current literals in
the model the SAT solver gives for $\neg c' \wedge c \wedge T \wedge F_k$.

The \verb,down, function then finds the deepest frame for which \verb,negCTI, is inductive, attempts to generalize
\verb,negCTI, relative to that frame with a recursive call (with a decremented value of \verb,r,)

\chapter{Evaluation}

\section{Benchmarking}
Benchmarks were taken for the performance of the different versions of the model checker and reference implementation
on fifteen handwritten examples, fifty examples from HWMCC'10, eleven (twenty) examples from HWMCC'11, and two (ten)
examples from HWMCC'13. For each example, forty benchmarking samples were taken, and if the elapsed time for
attempting to solve an example takes longer than ten minutes, the attempt is considered to have timed out.

Other than timing data, I also collected data about the number of frames needed to solve an example,
the average number of literals per clause, the number of CTIs discovered, the number of SAT-solver queries, and,
for the \emph{CTG} implementation, the number of CTGs discovered.

\section{Performance Impact of Variations}
%Discuss performance comparison of the naive implementation of the
%model checker and the final implementation of the model checker.

The overall performance of the model checker is heavily dependent on the size and number of SAT-solver queries;
profiling consistently reveals that functions in the Minisat module consume the most time when solving examples.

\subsection{Smaller Counterexamples to Induction}

Discovering smaller CTIs leads, as expected, to a smaller number of literals per clause and smaller SAT queries,
giving consistent performance improvements over the basic CTI-finding implementation for nontrivial
examples (i.e. examples that require finding counterexamples). The \emph{BetterCTI} version of the implementation
can solve seven more examples than the \emph{Basic} version without timing out.

\subsection{Propagation}

Also as expected, removing subsumed clauses results in a smaller number of literals per clause, resulting in
the \emph{BetterPropagation} version having slightly better performance than the \emph{BetterCTI} version.

\subsection{Counterexamples to Generalization}

The \emph{CTG} version that deals with CTGs performs the same as or worse than the \emph{BetterPropagation} version
on examples, most likely because the examples used are too small for the performance benefits of using CTGs to
eliminate more states to overcome the overheads of finding and proving negated CTGs. Similar results can be found
in the performance of the reference implementation with basic generalization and improved (CTG-using) generalization
on the same examples: for these examples, the reference implementation performs better with CTG-handling disabled.

\subsection{Priority Queues}

The advantage of using a priority queue rather than the basic recursive structure is that CTIs do not need
to be rediscovered: after a proof obligation $(s,i)$ is enqueued, until the algorithm fails or finds a fixed point,
the queue will always contain a proof obligation $(s,j)$ for $j \geq i$. When the proof obligation $(s,i)$
fulfilled at a certain depth $i$, $(s,i + 1)$ is then enqueued, If $s$ is a CTI for proving a property
$p$ at depth $i + 2$ (i.e. proof obligation $(\neg p, i + 2)$), by the time \verb,proveObligations, removes
proof obligation $(\neg p, i + 2)$ from the priority queue, $(s, i+1)$ has already been fulfilled, so the
CTI $s$ would not, after its initial discovery, need to be discovered again.

Even if $s$ is not a CTI for proving $p$ at depth $i + 2$, the proof obligations $(s, i+1)$ would still need to
be fulfilled before \verb,proveObligations, attempts to fulfill $(\neg p, i + 2)$.
\section{Performance Comparison}
%Discuss performance comparison of final implementation with
%IC3 reference implementation, taking into account differences between
%the implementations.

\chapter{Conclusion}

\section{Summary}
Summarize the project and accomplishments

\section{Further extensions}
Mention further extensions that could be implemented.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the bibliography
\addcontentsline{toc}{chapter}{Bibliography}
\bibliography{refs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the appendices
\appendix

\chapter{Project Proposal}

\input{proposal_noheader}

\end{document}

