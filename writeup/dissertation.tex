% Template for a Computer Science Tripos Part II project dissertation
\documentclass[12pt,a4paper,twoside,openright]{report}
\usepackage[pdfborder={0 0 0}]{hyperref}    % turns references into hyperlinks
\usepackage[margin=25mm]{geometry}  % adjusts page layout
\usepackage{graphicx}  % allows inclusion of PDF, PNG and JPG images
\usepackage{verbatim}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{docmute}   % only needed to allow inclusion of proposal.tex
\usepackage{listings}  % for formatting code
\usepackage{longtable}
\usepackage{csvsimple}
\usepackage{float}
\usepackage{color}
\usepackage[linesnumbered,figure,vlined]{algorithm2e}
\floatstyle{boxed} 
\restylefloat{figure}

\raggedbottom                           % try to avoid widows and orphans
\sloppy
\clubpenalty1000%
\widowpenalty1000%

\renewcommand{\baselinestretch}{1.1}    % adjust line spacing to make
                                        % more readable

\lstset{
  basicstyle = \small\ttfamily,
  language = Haskell,
  columns = fullflexible,
  keepspaces = true,
  showspaces = false,
  showstringspaces = false,
  keywordstyle = \color{blue}
}

\begin{document}
\SetKwProg{Fn}{Function}{:}{end}

\bibliographystyle{plain}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title


\pagestyle{empty}

\rightline{\LARGE \textbf{Lauren Pick}}

\vspace*{60mm}
\begin{center}
\Huge
\textbf{A Model Checker Using IC3} \\[5mm]
Computer Science Tripos -- Part II \\[5mm]
Homerton College \\[5mm]
\today  % today's date
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proforma, table of contents and list of figures

\pagestyle{plain}

\chapter*{Proforma}

{\large
\begin{tabular}{ll}
Name:                  & \bf Lauren Pick                           \\
College:               & \bf Homerton College                      \\
Project Title:         & \bf A Model Checker Using IC3             \\
Examination:        & \bf Computer Science Tripos -- Part II, 2016 \\
Word Count:            & \bf                                       \\
Project Originator:    & Lauren Pick                               \\
Supervisors:           & Dr Dominic Mulligan, Dr Ali Sezgin        \\ 
Supporting Supervisor: & Prof Alan Mycroft
\end{tabular}
}


\section*{Original Aims of the Project}

The original aims of the project were to implement the basic
IC3 algorithm as part of a model checker written in Haskell.
This model checker should be able to
solve several small example hardware models correctly.

\section*{Work Completed}

I implemented the basic IC3 algorithm as part of a new model checker,
which involved implementing several additional components: the AIGER parser,
MiniSat interface, and hardware model representation.
As an extension, I implemented other variants of the IC3 algorithm.
I benchmarked the variants on fourteen handwritten examples and
fifty-six examples from the Hardware
Model Checking Competition and compared results with those for
the IC3 reference implementation. The implementation of
the basic IC3 algorithm and its ability to solve
the handwritten examples meets the project's goals;
the implementation of other variants and their ability to solve
additional examples exceeds these goals.

\section*{Special Difficulties}

None.
 
\newpage
\section*{Declaration}

I, Lauren Pick of Homerton College, being a candidate for Part II of the Computer
Science Tripos, hereby declare
that this dissertation and the work described in it are my own work,
unaided except as may be specified below, and that the dissertation
does not contain material that has already been used to any substantial
extent for a comparable purpose.

\bigskip
\leftline{Signed [signature]}

\medskip
\leftline{Date [date]}

\tableofcontents

%\listoffigures

%\newpage
%\section*{Acknowledgements}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% now for the chapters

\pagestyle{headings}

\chapter{Introduction}

This project focuses on implementing the IC3 algorithm, a SAT-based model-checking
algorithm.
To provide context for the project,
I provide a brief introduction to formal verification and model checking, followed
by a discussion of symbolic model checking and SAT-based model checking.
I then highlight some of the important features of the IC3 algorithm and its more
recent uses.

Software and hardware bugs can be costly. The Pentium FDIV hardware bug cost an
estimated \$475 million \cite{pratt95}, and the Ariane 5 software bug cost
approximately \$370 million \cite{dowson97}.
The cost of such bugs catalyzed the adoption of new techniques for developing systems
that would help reduce the number of or mitigate the effects of residual bugs.
In particular, the Pentium FDIV bug encouraged the use of formal verification in
hardware design throughout the semi-conductor industry.

Formal methods is an umbrella term that refers to any application of mathematics or logic
in the improvement of the design or implementation of hardware or software systems.
One such technique falling under the ``formal methods'' banner is formal verification,
which focuses on proving properties of
systems.
For example, type checking provides a widely-used form of software verification,
proving that programs are well-typed. The formal verification technique of model
checking has been used to verify that circuits correctly implement the SRT
algorithm that the Pentium processors with the FDIV bug did not \cite{clarke96}.

Given a model and a specification of a system, a model checker will check whether or
not the system satisfies the specification.
Model checking is fully automated, unlike formal verification techniques that employ
Hoare Logic or proof assistants, which require user guidance.

\section{Symbolic Model Checking}

%Discuss BDD-based and SAT-based model checking techniques.
All model-checking approaches suffer from limitations on the size
of the systems they can model check in practice as a result of
the state explosion problem: the number of
states in a system can be (and often is) exponential in the
number of state variables \cite{clarke12}. 

The initial approach to the model checking problem involved explicitly
considering each reachable state in the model.
Symbolic model checking arose as a method of mitigating the effects of
the state explosion problem. By representing
states and the transition relation between them as logical formulas
(details of which are provided in Section \ref{prep:logic}),
symbolic model checking allows sets of states to be
represented efficiently as logical formulas involving state variables
instead of as an explicit list of each individual state in the set
\cite{mcmillan92}. 

Symbolic model checking was originally invented for use with ordered
binary decision diagrams (BDDs), data structures that provide an efficient
representation of propositional formulas. For a particular variable
ordering, a unique BDD represents each formula (and all equivalent formulas).
An implementation that only stores each BDD once and uses pointers appropriately
can result in less space being used.
The efficiency of BDDs in storing propositional formulas facilitates the model
checking of systems with larger numbers of states than could be handled
by explicit-state model checking \cite{mcmillan92}.

% Transition into talking about SAT-based model checking
The efficiency of BDD representations relies on choosing an appropriate
ordering, which can be computationally expensive, and in some cases,
there is no such ordering that results in a space-efficient BDD
\cite{biere99a}.

An alternative to BDD-based symbolic model-checking techniques are SAT-based
techniques, which use procedures for solving the Boolean satisfiability
problem and, unlike BDD-based methods, do not use the canonical representations
of propositional formulas.
Such techniques include bounded model checking (BMC)
\cite{biere99a}, $k$-induction \cite{sheeran00},
and the IC3 algorithm that is the focus of this project.

% Understanding IC3

\section{The IC3 Algorithm}

%Give context for the IC3/PDR algorithm, e.g. history and comparisons
%with other SAT-based model checking algorithms such as BMC and $k$-induction.

The IC3 (Incremental Construction of Inductive Clauses for Indubitable Correctness)
algorithm (also called Property-Directed Reachability \cite{een11}) is a state-of-the-art,
SAT-based model-checking
algorithm for proving the safety properties (i.e. properties that must hold
in all reachable states) of hardware \cite{bradley11}. In this section, I outline some of the
merits of the IC3 algorithm, with a description of IC3 following in Section
\ref{prep:ic3}.

The first implementation of the algorithm \verb,ic3, written by Aaron Bradley placed third in
the 2010 Hardware Model Checking Competition (HWMCC'10) \cite{hwmcc10},
a competitive event that receives model checker and benchmark submissions from
industry and
academia. Its performance at HWMCC'10 generated interest in the algorithm, and
since then, several variants of the algorithm have been developed.
%2015 paper

The IC3 algorithm has advantages when compared to other model checking
techniques such as $k$-induction and BMC that allow it to prove more
properties more efficiently. Unlike $k$-induction, the IC3 algorithm
discovers new invariants based on the safety property that it is trying to
establish of the system. As a result, these
invariants are more relevant to proving the property than those found
by $k$-induction \cite{bradley12}.
Furthermore, IC3 does not unroll the transition relation as $k$-induction
or other BMC-based methods do, but instead considers at most one step
of the transition relation at a time, leading to smaller,
simpler SAT queries. As a result, IC3 requires less memory than BMC-based
methods in practice \cite{bradley12}.

%Mention other applications of the IC3 algorithm, e.g. to checking
%LTL properties and to software model checking.

While the IC3 algorithm was designed for model checking safety properties of hardware,
it has been applied to model checking more
elaborate properties expressing temporal constraints (e.g. LTL and CTL
properties) and model checking software
\cite{bradley12,cimatti12}.
Results for more recent developments of software verification
techniques based on IC3 suggest that these techniques are competitive with
established software verification methods \cite{birgmeier14}.

\section{Project Aims}

The main aim in this project is to implement a basic form of the IC3 algorithm in
Haskell that can correctly check several
small examples. Additionally, the project is intended to provide an opportunity
for me to learn and use Haskell, to understand formal methods and especially model
checking more deeply, and to put into practice software engineering and design techniques.

The project aims have been achieved through the completion of the following:
\begin{itemize}
\item I gained background knowledge about Haskell, the IC3 algorithm, and software
development tools widely used in industry, such as Git (Chapter \ref{prep}).
\item I implemented the components of a model checker, including several variants of
the IC3 algorithm (Chapter \ref{impl}).
\item I empirically evaluated the model-checking capabilities of the implementations,
and attempt to draw some conclusions from my empirical data
(Chapter \ref{eval}).
\end{itemize}

I provide a summary of the completed work and ideas for
future work in Chapter \ref{conc}. With reference to the project aims submitted in my
project proposal, I have met and exceeded all aims.

\chapter{Preparation}
\label{prep}

This chapter describes the knowledge gained and plans made while preparing
to begin writing code for the project.
The preparation for the project involved learning purely functional
programming language Haskell (Section \ref{prep:haskell}),
an analysis that distinguishes the main components of the project
(Section \ref{prep:requirements}), choosing and learning how to use
the necessary tools for implementing the components of the project
(Sections \ref{prep:tools}, \ref{prep:aiger}, \ref{prep:minisat}),
and gaining the necessary knowledge about the symbolic representation
of hardware models
(Section \ref{prep:logic}) and the IC3 algorithm (Section \ref{prep:ic3}) to
adequately complete my project.
Throughout this chapter and subsequent ones, I collective refer to the model checker
variants implemented as part of this project as \emph{MC}.

\section{Haskell}
\label{prep:haskell}

All of the code for the project, with the exception of the C wrapper for the
MiniSat interface (described in Section \ref{impl:minisat})
is implemented in the purely functional
programming language Haskell \cite{haskell}.
I briefly explain some features of the
language that will make the rest of the report easier to follow.
I assume a working knowledge of Standard ML.

\paragraph{Functions}{
Unlike in Standard ML, there is no keyword in Haskell for defining functions. Instead,
Haskell functions are defined as a series of equations. Otherwise,
Haskell function definitions are similar to Standard ML function definitions with the
\verb,fun, keyword omitted, though curried functions are more common in Haskell than
Standard ML. Anonymous functions in Haskell are also defined similarly
as they are in Standard ML, using \verb,\, to bind variables analagously to Standard
ML's \verb,fn, keyword. Similarly to Standard ML, Haskell performs pattern matching
for function definitions and \verb,case, expressions. The pattern languages Standard
ML and Haskell are identical.
}

\paragraph{Types}{
Haskell is a strongly- and statically-typed language.
%Type constructors
Haskell type constructors and datatype declarations are largely similar to those in
Standard ML. A new Haskell datatype is declared using the \verb,data, keyword, an analogue
of Standard ML's \verb,datatype, keyword.
Haskell also provides record syntax for creating new record types, allowing components
of a product type to be named.

%Type signature syntax
Though Haskell compilers perform type inference, type
signatures can be (and, in cases where type inference cannot resolve
ambiguities, must be) provided. For example, the type signature for
the \verb,prove, function in \verb,IC3.hs,, a curried function that takes
a \verb,Model, and returns a function that takes a \verb,Lit, and returns a \verb,Bool,,
is \verb,prove :: Model -> Lit -> Bool,. Type signatures may begin with
constraints specifying that a polymorphic type variable occuring in the type
signature must be an instance of a certain type class.


%Type classes
Haskell's type classes facilitate ad hoc polymorphism \cite{hall94}.
Functions specified within the definition of a type class
must be supported for any type that is an instance of that type class.
Haskell compilers are able to automatically provide instances of standard
type classes for some types.
For example, a datatype that is an instance of a type class is the \verb,Lit, datatype
in the \verb,AigModel, module in \verb,Parser/AigModel.hs,:
\begin{lstlisting}
data Lit = Var Word | Neg Word | Boolean Bool deriving (Show, Eq, Ord)
\end{lstlisting}
The \verb,Lit, datatype is an instance of the \verb,Show,, \verb,Eq,, and
\verb,Ord, type classes, with the instances being automatically derived.
The \verb,Show, class contains the \verb,show, function (and related functions) that
converts instances to \verb,String,, the \verb,Eq, class contains
operators that allow equality testing of instances for
equality, and \verb,Ord, class contains comparison operators
that allow instances to be ordered.

Haskell's \verb,Monad, class encompasses composable
structures that describe computations. These computations
may have side effects, and Haskell programs use instances of the
\verb,Monad, class to achieve side effects such as I/O, which is
achieved using the \verb,IO, monad.

Monadic values can be created with the function
\verb,return :: Monad m => a -> m a,, which takes a Haskell
value of some type \verb,a, and returns an instance \verb,m, of the
\verb,Monad, class containing that value.
The \verb,>>=, infix operator (`bind') allows computations to be composed.
As expected given its type signature
\verb,(>>=) :: Monad m => m a -> (a -> m b) -> m b,, the function
takes a Monadic value containing a computation that produces a value of type
\verb,a, and a function that takes values of type \verb,a, and returns
monadic values, and returns the result of applying the function to the value.
The \verb,>>, infix operator, which has type signature
\verb,(>>) :: Monad m => m a -> m b -> m b,, also allows computations to be composed,
but the output of the first action is ignored by the second.

To avoid unwieldy code resulting from composing several
computations with \verb,>>=,, Haskell provides syntactic sugar
in the form of \verb,do,-notation, which allows monadic computations
to be written in an imperative fashion.

For example, the \verb,addClause', function in \verb,Minisat/Minisat.hs, could
be written as follows:
\begin{lstlisting}
addClause' solver clause =
  newMinisatVecLit >>=
  \veclit ->
    addToVecLit veclit clause >> 
    addMinisatClause solver veclit >>
    deleteMinisatVecLit veclit >>
    return solver
\end{lstlisting}
Using \verb,do,-notation results in more readable code:
\begin{lstlisting}
addClause' solver clause =
  do veclit <- newMinisatVecLit
     addToVecLit veclit clause
     addMinisatClause solver veclit
     deleteMinisatVecLit veclit
     return solver
\end{lstlisting}

Values inside the \verb,IO, instances of the \verb,Monad, class can be extracted
using \verb,unsafePerformIO, at the expense of guaranteed type safety; for pure
computations, the use of \verb,unsafePerformIO, does not compromise the type
safety of the program.
}

%List syntax
\paragraph{Lists and Tuples}{
List types and values in Haskell are denoted using square brackets, e.g.,
a list of \verb,Lit,s has type \verb,[Lit],.
Lists can be appended using the \verb,++, infix operator, and elements
can be prepended to lists using the \verb,:, infix operator.
For example, \verb.1:[2,3,4] ++ [5,6]. gives the Haskell equivalent to
\verb.1::[2,3,4] @ [5,6]. in Standard ML, both of which result in
the value \verb.[1,2,3,4,5,6]..

Tuples in Haskell are syntactically the same as in Standard ML, but the
Standard ML product type \verb,a * b * c, has Haskell type \verb.(a, b, c).
as its analogue.
}

%Modules
\paragraph{Modules}{
A Haskell program consists of modules, which organize code.
Modules (or just selected functions from modules) can be imported into other
modules, which is how library functions can be used. Modules can be referred
to (e.g. in import statements) by names that incorporate where they are
stored in the directory structure. For example, the \verb,Model, module in file
\verb,Model/Model.hs, can be referred to as \verb,Model.Model,.
}


\section{Requirements Analysis}
\label{prep:requirements}

%Describe the requirements for the project: AIGER parser, Minisat interface,
%transition system representation, algorithm implementation.

The model checker \emph{MC} requires a way of taking input models and, since
the IC3 algorithm uses a SAT solver as an internal subcomponent, also
requires a way to solve SAT queries.
I chose the AIGER format for representing the hardware models and the
MiniSat SAT solver for answering SAT queries, resulting in a need for an
AIGER parser and a Haskell interface to MiniSat. The choice of
the AIGER format allows \emph{MC} to be run on examples from
the Hardware Model Checking Competition (HWMCC), since this is the format used
to specify examples in the competitions. I chose the MiniSat SAT
solver to allow for better comparison of \emph{MC}
with Aaron Bradley's reference implementation of IC3 (\emph{IC3ref})\cite{refic3}.
Because MiniSat is the solver used by \emph{IC3ref}, using it as the solver
for \emph{MC} removes the
choice of SAT solver as a variable to consider when comparing performance,
reducing confounding factors.

Given that the model checking algorithm deals with transition systems
(discussed in Section \ref{prep:logic}), the implementation also requires a representation of
transition systems, which should correspond to the input hardware model.
A further requirement is the implementation of the
IC3 algorithm itself.

The main required components are thus the AIGER parser, MiniSat interface,
transition system representation, and IC3 algorithm implementation.

\section{Tools Used}
\label{prep:tools}

I used a variety of tools to employ software engineering practices, such
as version control and testing, and to otherwise ease the development of
the project's code.

\paragraph{Git}{
The Git version control system \cite{git}
was used for managing the project's code, and
GitHub \cite{github}, a widely-used hosting service for Git repositories, was used to
keep backups of the code.
The previous versions maintained by the system proved useful in
the development of the code, and branching and merging capabilities were
useful for organizing variations of the model checker.
I used Git submodules, which allow the inclusion of other Git projects within another
project, to include MiniSat within the project, enabling easier
acquisition of project dependencies (i.e., MiniSat can be obtained by running
\verb,git submodule init, after running \verb,git clone, to clone the repository).}

\paragraph{Haddock}{
The Haddock \cite{haddock} documentation tool for Haskell was used to generate documentation
for the code. Haddock automatically generates documentation in
several formats (e.g. HTML) from annotated Haskell code. It is commonly
used to document Haskell code, being used for most packages available
on the Haskell package database Hackage.
}

\paragraph{HUnit}{
HUnit \cite{hunit} is a framework for writing unit tests in Haskell based on the
JUnit framework \cite{junit} for unit testing in Java.
HUnit tests can be specified by using functions
that return the \verb,Assertion, type to write \verb,TestCase,s. For example, the
\verb,assertBool :: String -> Bool -> Assertion, function takes a \verb,String,
that gives an error message and a \verb,Bool, value, and raises an exception (with
the error message) if the \verb,Bool, is not \verb,True,, so the
following expression gives a \verb,TestCase, that tests that function
\verb,isEven, returns \verb,True, when called with parameter 12:
\begin{lstlisting}
TestCase (assertBool "Error: (isEven 12) results in False" (isEven 12))
\end{lstlisting}

The \verb,Test, datatype in HUnit allows \verb,Test,s to be grouped
and built up hierarchically. Tests that have been assembled into a
single tree can then be treated as a test suite, and the whole tree
of unit tests can be run. See Section \ref{eval:solving} for more on testing.}

\paragraph{Criterion}{
Criterion \cite{criterion} is a library for performing benchmarking in Haskell.
Criterion can output benchmarking results in any format specified in the \verb,.tpl,
template format, and by default outputs HTML.
The \verb,.tpl, file can be configured such that
Criterion can, e.g., output benchmark sample results to a CSV file, as the
\verb,.tpl, for benchmarking this project was configured.}

\paragraph{Cabal}{
Cabal \cite{cabal} is the standard package and dependency management system for Haskell,
where a package may be a library or a complete piece of executable software.
A \verb,.cabal, file in the root directory of a project specifies
information about the Cabal package, such as its version and dependencies,
The \verb,.cabal, file may contain several sections, such as a
\verb,library, section, describing the modules in the package that should be
exposed in the library provided by the package or an \verb,executable, section,
which has fields for specifying the Haskell file containing the \verb,Main,
module and for specifying other Haskell files used by the program.
The \verb,.cabal, file for this project also uses the \verb,Test-Suite, section
to allow the HUnit test for the project to be run in a standard way (by running
\verb,cabal test, in the root directory of the package) and the \verb,Benchmark,
section to allow the benchmarking program to be run in a standard way as well
(by running \verb,cabal bench, in the root directory of the package).

Cabal also uses a Haskell file \verb,Setup.hs, to give further information
about how to build the package. For example, the \verb,Setup.hs, file
for this project compiles the C and C++ code for MiniSat and the MiniSat
wrapper before Cabal attempts to build the rest of the project, so the
files necessary for linking are already present.

The use of Cabal enables the project to be built easily on different platforms,
since Cabal provides a standard method for building the package that works
across platforms.}

\paragraph{hsc2hs}{
The \verb,hsc2hs, preprocessor \cite{hsc2hs} eases the writing of Haskell bindings to C
code by enabling the programmer to write a \verb,.hsc, file containing
macros that the preprocessor can expand to, e.g., pointer offsets. The
\verb,hsc2hs, expands the macros in a \verb,.hsc, file to produce a
Haskell source (\verb,.hs,) file that can then be compiled with a Haskell compiler and run.
}

\paragraph{HLint}{
The HLint tool \cite{hlint} is a linting tool that suggests improvements to Haskell source
code to improve the style of the code.
The incorporation of HLint suggestions in
this project resulted in simpler, more readable code.
}

\paragraph{AIGER Utilities}{
Several tools provided in AIGER Utilities \cite{aiger} were used in this project.
The
AIGER parser provided was used for comparison with and as an alternative
to the parser developed as part of this project. 

The Aiger Utilities' tools to convert between formats for specifying
hardware models eased the specification of new models that would
be compatible with the model checker implementations,
which accept only AIGER-formatted inputs.
In particular, I used the {\tt bliftoaig}
tool to convert circuits specified using the Berkeley Logic Interchange Format
to circuits specified using the binary AIGER format, and the {\tt aigtoaig} tool,
to convert between the ASCII and binary AIGER formats. }

\paragraph{MiniSat}{
MiniSat \cite{minisat,een05}
is a SAT solver implemented in C++ that solves Boolean satisfiability problems
posed in conjunctive normal form. Further details are given in Section \ref{prep:minisat}.
}

\section{Symbolic Representation}
\label{prep:logic}

Symbolic model checkers rely on the representation of the underlying system as
logical formulas that describe the behavior of the system as one-step transitions
between states. %Propositional logic formulas define transition systems and states.

I give a brief review of concepts in logic before formally defining transition systems
and explaining how propositional logic formulas represent states. I assume basic
knowledge of propositional logic throughout.

\paragraph{Logic}{
A variable is a propositional symbol that can be assigned Boolean values {\it True}
or {\it False}. A \emph{literal} is defined as being either an atom $a$ (which can
be a variable or Boolean value) or its negation $\neg a$.

A \emph{cube} is defined to be a conjunction of literals and may be represented as the set
of literals that occur in it. Similarly, a \emph{clause} is a disjunction of literals that
may also be represented as the set of literals that occur in it.

Given a cube $c$, a cube $d$ is a \emph{subcube} of $c$ (written $d \subset c$)
iff the set of literals in $d$ are a subset of the set of literals in $c$.
Similarly, given a clause $c$, a clause $d$ is a \emph{subclause} of $c$ (also
denoted $d \subset c$) iff the set of literals in $d$ are a subset of
the literals in $c$.

From de Morgan's laws, cubes and clauses are duals; the negation of a cube is the
clause specified by the set resulting from negating each literal in the cube
and vice-versa.

A propositional formula is in \emph{conjunctive normal form} (CNF) iff it is a conjunction 
$\bigwedge_i D_i$ of disjunctions $D_i$ of literals (i.e. clauses). A set of clauses
can be interpreted as the CNF formula resulting from the conjunction
of the clauses. Any propositional formula can be easily converted to an equivalent CNF
form.}

\paragraph{Transition Systems}{
A \emph{transition system} is a tuple $(i,x,I,T)$ consisting of a set of input
variables $i$, state variables $x$, an initial
set of states represented by the logical formula $I(x)$ and
a transition relation represented by the logical formula $T(i,x,x')$,
where $x'$ is the set of next-state variables.

For each state variable $v$, $v'$ denotes the corresponding next-state variable.
For example, a transition relation that states that all variables that are
currently {\it True} should become {\it False} in the next state is as follows:
$$T(i,x,x') = \bigwedge_{v \in x} (v \Rightarrow \neg v').$$
In a similar fashion, for a formula $X$ involving only current-state variables,
the formula $X'$ is the formula $X$ where each current-state variable $v$ has
been replaced by the corresponding next-state variable $v'$.

Given transition system $(i,x,I,T)$, a logical formula $C$ is, by definition,
\emph{inductive relative} to logical formula $F$ if both
$I \Rightarrow C$ and $F \wedge C \wedge T \Rightarrow C'$ hold.
Relative inductiveness plays a key role in the IC3 algorithm.
}

\paragraph{States}{
A single state of the transition system (or a singleton set containing that state)
is specified through the assignment of all state variables in the transition system
to Boolean values, where a \emph{complete} assignment is represented as a cube such
that every variable appears in the formula exactly once.
An incomplete assignment of variables in the transition system is a cube such that
at least one variable in the transition system does not appear in the cube. Such an
assignment $c$ specifies the set of cubes $\{a \in{\it Full~Assignment}|c \subset a\}$,
where ${\it Full Assignment}$ is the set of complete assignments to the variables in the
transition system.
More generally, any logical formula $b$ involving the variables in the transition
system gives the set of states
$\{a \in {\it Full~Assignment} | a \wedge b~{\rm is~satisfiable}\}$.

For a logical formula $B$, a \emph{$B$ state} is a state that is in the set of states
represented
by $B$. A set of states $s$ is said to be \emph{reachable}
in $k$ steps of the transition relation iff there exist input variables and
states $s_0, \ldots, s_k$ such that
$s_0$ is an $I$ state and $s_j \wedge T \Rightarrow s_{j + 1}$ for $1 \leq j < k$,
where $T$ represents the transition relation of the transition system.

}


\section{Model Specification}
\label{prep:aiger}
%Describe the AIGER (old and new version) and BLIF formats and
%{\tt bliftoaig} from the AIGER utilities.

%Comments?

I used both the AIGER format and Berkeley Logic Interchange Format (BLIF)
to specify fourteen example hardware models.
The models that the model checker accepts as input
are specified using the AIGER format;
however because using the AIGER format to specify larger models was cumbersome,
I specified some models using BLIF and converted them to AIGER format
using the Aiger Utilities' \verb,bliftoaig, tool. Given that one of
the project's components is an AIGER parser, I describe the AIGER format
in more depth.

The AIGER format has several versions, with each providing
a method of specifying hardware as
And-Inverter Graphs with latch elements providing single clock-tick
delays: all circuits are modeled as a graph of nodes consisting only of
AND gates, inverters, and latches, where the latches behave like D
flip-flops, outputting the value of the current input at the next
clock tick.

The AIGER format has both an ASCII and a binary version, either of which
can be used as inputs to this project's model checker. The ASCII
format is more flexible and human readable, imposing fewer constraints
on the ordering of components within the input file. For example, an
AND gate with variable name {\tt 20} may be specified before an AND gate with
variable name {\tt 11} in the ASCII format, but AND gates must be specified in
ascending order of their variable names in the binary format.
%Another
%example is that AND gates' inputs can occur in any order in the ASCII
%format, but the binary format encodes AND gates under the assumption
%that inputs' indices are in ascending order.
The binary version's assumptions on component ordering allow the format
to be more compact. The HWMCC examples use the binary format.

A new version of the AIGER format is currently under development \cite{aiger}, with
examples from HWMCC'14 onward using the new version. The AIGER parser component
of this project handles both the old and new versions of the format.

I provide a description of how variables are represented in all AIGER formats
followed by a description of the old ASCII version of the AIGER format, which
is sufficient to understand the handwritten examples written directly
in AIGER format. Descriptions of the other formats can be found in Appendix
\ref{aiger}.

\paragraph{AIGER Variables}{
AIGER identifies each Boolean variable with a positive integer.
Variables themselves are not represented directly in AIGER format; instead, literals,
which identify wires and their values in a circuit,
occur in the format. Nonnegative numbers called indices are used to represent literals.

For any variable named $x$, the index for positive literal $x$ is given by
$2 \times x$, and the index for negative literal $\neg x$ is given by
$2 \times x + 1$, i.e. a function to map from variable names $x$ and a Boolean
value $b$ giving the sign of the literal would be as follows:
$${\it index}(x, b) =
\begin{cases}
2x & {\rm if}~b \\
2x + 1 & {\rm otherwise}
\end{cases}$$
The indices 0 and 1 are used to represent the constant Boolean values {\it False}
and {\it True}, respectively.

Any index above 1 represents a literal. 
Given that even indices represent positive literals, and odd indices
represent negative literals, the representation allows
the least significant bit of an index to give the sign of a literal
and a single bitwise right shift to find the variable name for the literal.

\paragraph{Old ASCII version}{
All AIGER files in the old version begin with a header of the form
\begin{verbatim}
V M I L O A
\end{verbatim}
where
\begin{itemize}
\item \verb,V, specifies the format type, with \verb,aag,, specifying that the file is in the ASCII format and \verb,aig,, specifying that the file is in the binary format.
\item \verb,M, specifies the maximum index of a variable.
\item \verb,L, specifies the number of latches.
\item \verb,O, specifies the number of outputs.
\item \verb,A, specifies the number of two-input AND gates.
\end{itemize}

The different components are specified after the header
in the order that their counts are given in the header.

In the ASCII version of the format, an input is specified by the
index giving the positive literal for its corresponding variable name,
and an output are specified similarly by a single index (that may represent
a literal of any sign).

A latch has initial value 0 (i.e., {\it False}) and is specified by the
index representing the positive literals for its corresponding variable name
followed by the index for its next-state value.
An AND gate, which is always binary,
is specified by the index representing the positive literal
for its variable name and the two indices that specify its input values.

\begin{figure}[t]
\centering
\includegraphics[width=100mm]{circuit.png}
\caption{The circuit represented in {\tt examples/simple3.aag}.}
\label{aagCircuit}
\end{figure}

For example, the circuit in Figure \ref{aagCircuit} is represented
as follows (comments to the right are not part of the specification):
\begin{verbatim}
aag 3 0 2 1 1
2 3              D-latch (output wire has index 2)
4 2              D-latch (output wire has index 4)
6                Output
6 2 4            AND gate
\end{verbatim}
The circuit has no inputs, two latches with indices $2$ and $4$ and one AND gate
with index $6$ that takes the outputs of the two latches as inputs.
The output of the whole circuit is the output of the AND gate.
}


\section{MiniSat}
\label{prep:minisat}

MiniSat is the SAT solver used by the \emph{MC} implementations. The creation of a
working interface to MiniSat required some background knowledge of how MiniSat
works. The MiniSat code explained in this section is in C++.

To solve a SAT query, MiniSat creates an instance of a \verb,Solver, object,
which contains a set of variables, sets of clauses, and possibly a model or a conflict vector.
The set of variables in the \verb,Solver, gives all the variables that may appear in
a SAT query, the set of clauses forms the SAT query, and the model or conflict vector
gives further information about the last SAT query made.

In addition to a \verb,Var, type for representing variables, MiniSat has a \verb,Lit, type for
representing literals, and MiniSat represents sets of clauses as \verb,vec<Lit>,s,
vectors of literals. The set of clauses in a \verb,Solver, together represent a CNF query.
If the \verb,Solver,'s \verb,solve(), function is called,
the resulting \verb,bool, indicates whether the query is satisfiable or not. The
\verb,solve(), function is overloaded so that it may also take an assumption \verb,vec<Lit>*, as
an argument. The literals in the assumption vector must hold in addition to the CNF query formed
by the \verb,Solver,'s clauses: if the \verb,Solver,'s clauses form some CNF query $C$ and
\verb,solve(assumps), is called, where \verb,assumps, represents some set $A$ of literals,
then the SAT query is $C \wedge \bigwedge_{l \in A} l$.

If there has been at least one query made of the \verb,Solver, object, and the query was
satisfiable, the \verb,Solver,'s \verb,model, variable points to a set of variable assignments
for that SAT query.
If there has been at least one query made of the \verb,Solver, object, and the query was
unsatisfiable, the \verb,Solver,'s \verb,conflict, variable points to a set of literals that
contains the assumed literals that caused the query to be unsatisfiable.

\emph{MC} uses instances of \verb,SimpSolver,, a subclass of the \verb,Solver, class
that does simplification and returns full assignments, providing more useful results
for the queries that IC3 makes.

\section{The IC3 Algorithm}
\label{prep:ic3}
%Describe how the IC3 algorithm works when trying to prove a model has a property
%$P$.
I now describe the basic IC3 algorithm and some of its extensions, which are
necessary to understand the following chapters.
Given a hardware model (i.e. a finite-state transition system $(i,x,I,T)$) and a
safety property $P$, IC3 aims either to prove inductively that $P$ holds
at all reachable states from the initial state or
to find a reachable $\neg P$ state.
The pseudocode in Figure \ref{overview} gives an overview of the basic IC3 algorithm.	

\begin{algorithm}[t]
\DontPrintSemicolon
\Fn{prove$((i,x,I,T),P)$}{
  \lIf{$\neg (I \Rightarrow P)$ \label{initiation}}{
    \Return{False}
  }
  $F_0 := I$ \;
  $k := 0$ \;
  \While{True \label{main}}{
    \eIf{$F_k \wedge T \Rightarrow P'$ \label{consecution}}
    {create frame $F_{k + 1}$ initialized to $\emptyset$ \label{create} \;
     $k$ := $k + 1$ \;}
    {\While {$\neg (F_k \wedge T \Rightarrow P')$ \label{reconsec}}{
        ${\it cti} := {\it nextCTI}(F_k \wedge T \Rightarrow P')$ \label{CTI} \;
        \lIf{{\it proveNegCTI}$((i,x,I,T),{\it cti},k - 1)$ \label{negCTI}}{$F_k$ := $F_k \cup \{\neg{\it cti}\}$}
        \lElse{\Return{False}}}} \label{Unsafe}
    \For{ i = 0 \KwTo $k - 1$ }{ \label{forprop}
      $F_{i + 1} := F_{i + 1} \cup \{c \in F_i | F_i \wedge T \Rightarrow c'\}$ \label{push} \;
      \lIf {$F_i = F_{i + 1}$}{\Return {True}} \label{fixed}
    }
  }
}
\caption{An overview of the IC3 algorithm. Frames are assumed to be passed by reference.}
\label{overview}
\end{algorithm}

The IC3 algorithm maintains a set of $k + 1$ frames $F_0,\ldots,F_k$, where
each frame $F_i$ is a set of clauses whose disjunction represents an
overapproximation of the set of states reachable by the transition
system in at most $i$ steps from the initial state
(so, for example, $F_0$ is just the initial state set $I$, as seen
in the pseudocode).
The deepest frame $F_k$ in the set of frames is the \emph{frontier}.

%Initiation query
The \emph{initiation query} $I \Rightarrow P$ (line \ref{initiation}) checks that
the property holds in the initial state $I$.
%This query is run once at the start of
%the algorithm for the desired property.
If it fails (i.e. if it is {\it False}), then the algorithm terminates,
as a state in which $\neg P$ holds is reachable in 0 steps.
If it succeeds, then the algorithm proceeds to its main loop.

The main loop of the algorithm is the while loop beginning on line \ref{main}.
The algorithm only exits the loop when it has determined whether or not the
safety property holds at all reachable states in the model.

%Consecution query
The \emph{consecution query} $F_k \wedge T \Rightarrow P'$ (line \ref{consecution}) is
is used to check whether the property $P$ necessarily holds in the next
frame. If it does, then IC3 creates a new
frontier frame $F_{k + 1}$ (line \ref{create}).
%Describe what happens when a consecution query fails

If a consecution query $F_k \wedge T \Rightarrow P'$ fails, then
there is an $F_k$ state $s_k$ and a $\neg P'$ state $s_{k + 1}$ with $T(i,s,s_{k + 1})$.
The state $s_k$ is called a \emph{counterexample to induction} (CTI) state.
The algorithm then aims to refine the approximation $F_k$ of the set of states
reachable in at most $k$ steps by showing that all states that are
reachable in at most $k$ steps are $\neg s_k$ states.

The call to {\it nextCTI} in line \ref{CTI} finds the counterexample to
induction state $s_k$ when passed parameters $s = s_k$ and $j = k$.
The call to {\it proveNegCTI} on line \ref{negCTI}
attempts to prove that $\neg s$ is inductive relative to $F_{k - 1}$,
in which case all $F_k$ states are necessarily $\neg s$ states, so $\neg s$ can
be added to the set of $F_k$ clauses.

%The {\it proveNegCTI} algorithm works similarly to the
%while loop on line \ref{reconsec}.
For as long as the query
$F_k \wedge \neg s \wedge T \Rightarrow s'$ is unsuccessful,
the algorithm extracts a CTI cube and
calls {\it proveNegCTI} to show that the counterexample is
inductive relative to frame $F_{j - 1}$ so that the negated
counterexample can be added to frame $F_j$.
If the shallowest possible depth $j = 0$ is reached, then
{\it proveNegCTI} fails and returns {\it False}.

The {\it proveNegCTI} pseudocode in Figure \ref{proveNegCTI}
does not explicitly check for $I \Rightarrow
\neg s$. An explicit check is unnecessary because if
$I \Rightarrow \neg s$ does not hold, then eventually ${\it proveNegCTI}$
will be called recursively with $j = 0$ and the attempt to show that
$\neg s$ is relatively inductive to $F_j$ fails.

\begin{algorithm}[t]
\DontPrintSemicolon
\Fn{proveNegCTI$((i,x,I,T),s,j)$}{
  \lIf{$j = 0$}{\Return{False}}
  \While{$\neg(F_j \wedge \neg s \wedge T \Rightarrow \neg s')$}{
    ${\it cti} := {\it nextCTI}(F_j \wedge \neg s \wedge T \Rightarrow \neg s')$ \;
    \lIf{{\it proveNegCTI}$((i,x,I,T),{\rm cti},j - 1))$}{$F_j$ := $F_j \cup \{\neg{\it cti}\}$}
    \lElse{\Return{False}}
  }
}
\caption{Pseudocode for proving negated CTIs.}
\label{proveNegCTI}
\end{algorithm}

If $\neg s_k$ cannot be proven to hold at each of $k$ steps of
the transition relation from the initial state, i.e. the state $s$ is in the actual
set of states reachable in $k$ steps from the initial state, then a $\neg P$ state
is reachable in $k + 1$ steps from the initial state; the safety property does not
hold, and the algorithm terminates (line \ref{Unsafe}).

Because there may be several CTIs, it is necessary to
perform the consecution query again (line \ref{reconsec}). If it fails again,
the process of finding the new counterexample to induction state(s) $d$ and trying to
prove that $\neg d$ holds at depth $k$ repeats. Upon the success of the consecution
query, the algorithm moves to the propagation phase.

\emph{Pushing} a clause $c$ from a frame $F_i$ to frame $F_{i + 1}$ refers to the act
of setting $F_{i + 1} := F_{i + 1} \cup \{ c \}$ with $c \in F_i$.
A clause $c$ can be pushed from a frame $F_i$ to the next frame $F_{i + 1}$
if the consecution query $F_i \wedge T \Rightarrow c'$ holds.
The propagation phase of the algorithm goes through the set of frames
$F_0, \ldots, F_k$, and, for every $F_i$ with $0 \leq i < k$ (line \ref{forprop}),
pushes all the clauses that it can from $F_i$ to $F_{i + 1}$ (line \ref{push}).

If $F_i = F_{i + 1}$ holds for any $i$ at any point, then a fixed point has
been found: frames at any greater depth than $i$ will continue to be the
same as $F_i$, since all the the clauses in $F_i$ and therefore $F_{i + 1}$
can be pushed.
Because $F_i$ contains the safety property $P$ as one of its clauses,
this means that $P$ holds in all reachable states from the initial state,
and the algorithm terminates (line \ref{fixed}). Because the number of
clauses in each frame $F_i$ decreases monotonically as $i$ increases and the
frame $F_0$ can only have finitely many states, the algorithm always
terminates.

\subsection{Inductive Generalization}

After showing that a negated CTI state $\neg s$ is relatively inductive to a
frame $F_i$ and adding the clause $\neg s$ to frame $F_{i + 1}$, the state
$s$ is eliminated from the approximation $F_{i + 1}$ of the set of states
reachable in at most $i + 1$ steps. An improvement can be made by generalizing
$s$ to a set of several states $c$ rather than a single state, and treating
$c$ as the CTI. If $\neg c$ is successfully proven to be relatively inductive
to $F_i$, then adding it to frame $F_{i + 1}$ eliminates several states (i.e.,
all $c$ states) at once rather than only $s$. Because the cube $c$
is chosen so that $\neg c \Rightarrow \neg s$, at least one CTI state
has been removed from $F_{i + 1}$, and because $c$ contains several states,
it is possible that several CTIs may have been removed from $F_{i + 1}$
by adding the clause $\neg c$ to it. The process of finding such a cube $c$
is referred to as \emph{generalization}, and the best such $c$ is the
one such the $\neg c$ is the minimal inductive subclause for $F_i$ and $\neg s$.

\subsection{Minimal Inductive Subclauses}
The \emph{minimal inductive subclause} for a frame $F_i$ and a clause $\neg s$ that
is inductive relative to $F_i$
(i.e. $F_0 \Rightarrow s'$ and $F_i \wedge T \wedge s \Rightarrow s'$)
is a clause $\neg c$ whose
literals are the smallest subset of the literals in $\neg s$ such that
$\neg c$ is also inductive relative to $F_i$.
The minimal inductive subclause can be found by dropping each literal
in $\neg s$ in turn and checking the resulting clause.

The checking phase (described by {\it down} in Figure \ref{mic},
which takes a clause ${\it cls} = \neg s$ and a depth $i$ as arguments)
performs the normal queries
for determining whether the subclause is inductive relative to
$F_i$: for a subclause $t = \neg s \ \{l\}$ found by dropping
literal $l$ from $\neg s$, it checks that
$I \Rightarrow t$ and $F_i \wedge t \wedge T \Rightarrow t$ both hold.

If both formulas hold, then the literal $l$ can be dropped from $\neg s$.
If only the formula $F_i \wedge t \wedge T \Rightarrow t$ fails to hold, then
it is possible that expanding the set of states in $t$ by removing some of the
literals in $t$ would result in a clause that is inductive relative to $F_i$.
If $I \Rightarrow t$ fails to hold, then removing any literals in $t$ to
obtain a subclause $u \subset t$ would still result in the query $I \Rightarrow u$
failing, since it is the case that $u \Rightarrow t$.

The formula $F_i \wedge t \wedge T \Rightarrow t$ not holding indicates
that there is a predecessor to a $\neg t$ state that is a $F_i \wedge t$ state.
This predecessor state $p$ can be extracted from the SAT query for
$F_i \wedge t \wedge T \Rightarrow t$ in the same way that CTIs are found.
The clause $t$ can then be expanded to the clause $t \cap \neg p$
formed by taking the common literals in $t$ and $\neg p$.
The checking phase then repeats, checking the expanded clause $t \cap \neg p$.

\begin{algorithm}[t]
\DontPrintSemicolon
\Fn{mic(cls,i)}{
  \ForEach{literal l in cls}{
    $subcls := cls \setminus \{l\} $\;
    \If{${\it down(subcls, i)}$}{
      $cls := subcls$ \;
    }
  }
  \Return{cls} \;
}
\Fn{down(cls, i)}{
  \lIf{$\neg (I \Rightarrow {\it cls})$}{\Return{False}}
  \lIf{$F_i \wedge {\it cls} \wedge T \Rightarrow {\it cls}'$}{\Return{True}}
  $p$ := $F_i \wedge t$ state such that $F_i \wedge t \wedge p \Rightarrow \neg t'$ \;
  {\it cls} := $cls \cap p$\;
  \Return{down(cls,i)} 
}
\caption{The algorithm for finding the minimal inductive subclause. Clauses are assumed
to be passed by reference.}
\label{mic}
\end{algorithm}

%Finding the minimal inductive subclause can be computationally
%expensive, so it is often approximated in practice.

An improvement to the generalization provided by finding minimal
inductive subclauses in this way incorporates the use of counterexamples
to generalization \cite{hassan13}.

\subsubsection{Counterexamples to Generalization}

Checking if a subclause $\neg c = s \setminus \{l\}$ of a clause $\neg s$ is inductive
relative to a frame $F_i$ involves checking if
$F_i \wedge T \wedge \neg c \Rightarrow \neg c'$ holds.
If the implication does not hold, then $\neg c$ is not inductive relative to
$F_k$. In the original method of generalization described above,
this means that $\neg s$ cannot be generalized to $\neg c$, and generalization
proceeds without dropping $l$.

The reason the query
$F_k \wedge T \wedge c \Rightarrow c'$ is unsatisfiable might be that
$F_k$ is too broad an approximation, similarly to why a consecution
query at $F_k$ might fail. As with consecution queries, discovering a
new clause that can be added to $F_k$ may allow the queries that
check for relative induction to succeed, and the discovery of this
clause can be directed by a counterexample extracted from the
SAT solver after the query for $F_k \wedge T \wedge c \Rightarrow c'$.

The counterexample state in this case is called a \emph{counterexample
to generalization} (CTG), and proving the negated CTG to be true at
frame $F_k$ allows $s$ to be generalized to $c$.


\chapter{Implementation}
\label{impl}

This chapter describes my implementation of the \emph{MC} model checkers.
The implementation can be broken up into four main components: the AIGER parser
(Section \ref{impl:aiger}), the
MiniSat interface (Section \ref{impl:minisat}), the hardware model representation
(Section \ref{impl:representation}), and the model checker
(Section \ref{impl:modelchecker}).
The implementation of the AIGER parser, MiniSat interface, and \emph{Basic} version
of the IC3 algorithm satisfy the project aims to implement these components. As
extensions, I have implemented additional variants of the IC3 algorithm.

The variants of the model checker component differ
in overall structure, the finding of CTIs, the way that propagation is performed, and
the way that CTIs are inductively generalized. The variants and the
differences among them are given in the following table:\\

\begin{tabular}{| l | p{3.5em} | p{3em} | p{4.5em} | p{5em} | p{6em} |}
\hline
& Priority Queue & Smaller CTIs & Subsumed Clauses & Basic Generalization & Generalization with CTGs\\
\hline
\emph{Basic} & & & & \checkmark & \\
\emph{BetterCTI} & & \checkmark & & \checkmark & \\
\emph{BetterPropagation} & & \checkmark & \checkmark & \checkmark &\\
\emph{PriorityQueue} & \checkmark & \checkmark & \checkmark & \checkmark & \\
\emph{CTG} & & \checkmark & \checkmark & & \checkmark \\
\hline
\end{tabular}\\



%I now briefly explain the motivations for the deviations from the \emph{Basic}
%implementation. The details of these deviations are given in Section \ref{impl:modelchecker}.
The ``Priority Queue'' alteration was based on observations that keeping
track of proof obligations with priority queues is more efficient than the simple
recursive implementation of the IC3 algorithm \cite{een11,griggio14}.
The ``Smaller CTIs'' alteration was based on the improvement of finding
predecessors to counterexamples that describe sets of several states rather
than singleton states \cite{griggio14}.
The ``Subsumed Clauses'' alteration was based on the observation that subsumed clauses slow
down the SAT-solver and should be eliminated to achieve better performance
\cite{een11}.
The ``Generalization with CTGs'' alteration was based on the description of an algorithm
that improves upon the basic inductive generalization algorithm \cite{hassan13}.

\section{Parser}
\label{impl:aiger}
%Discuss the implementation of the AIGER parser. In particular, mention
%the handling of both the older and newer AIGER format versions for both
%the ASCII and binary versions of the format and the representation
%of AIG models.

The relevant files for this section can be found in the \verb,Parser, directory.
The parser component parses ASCII or binary-formatted AIGER files and
assumes that the new format is used (because the new format is backward compatible)
. Justice properties and fairness constraints are not handled by \emph{MC}, so
the parser ignores them.

The \verb,Parser.AigerParser, module, which implements the parser in Haskell, and
the \verb,Parser.AigerTools, module, which calls the Aiger Utilities' parser's functions,
each convert the AIGER file into the \verb,Model, data structure in \verb,Parser.AigModel,,
which stores the components specified in the AIGER file.

\subsection{Model}

The \verb,Model, data structure stores the number of variables and
number of inputs. It also stores lists of literals that represent the outputs, bad states,
and invariant constraints. The data structure also stores latches and AND gates as
lists of literal lists. I discuss the representation of literals, latches, and
AND gates.

Literals are represented by \verb,Lit,s (defined in Section \ref{prep:haskell}),
which store decoded versions of AIGER indices. The {\tt Lit} datatype
in {\tt Parser.AigModel} has the following constructors:
\begin{itemize}
\item \verb,Boolean,, which takes a \verb,Bool, argument;
\item \verb,Var,, which takes a \verb,Word, argument; and
\item \verb,Neg,, which takes a \verb,Word, argument.
\end{itemize}
\verb,Boolean,s represent the Boolean values corresponding with AIGER indices 0 and 1,
\verb,Var, represents the positive literal of the variable whose name is given by the
\verb,Word, it takes as an argument, and \verb,Neg, represents the negative literal
of the variable whose name is given by the \verb,Word, it takes as an argument.
Variable names are adjusted (by subtracting 1) so that they start at 0.
For example, the index 3 read from an AIGER file is parsed to \verb,Neg 0,;
the odd index 3 indicates that it is a negative literal of the variable 1, and
subtracting by 1 gives the new variable name 0.

Latches and AND gates are represented using three-element \verb,[Lit],s. For latches,
\begin{itemize}
\item the first element gives the variable name of the latch (as a positive literal),
\item the second gives the next-state literal, and
\item the final element gives the initial state
of the latch.
\end{itemize}
For example, the latch from Figure \ref{aagCircuit} represented by \verb,2 3, is parsed
to \verb.[Var 0, Neg 0, Boolean False]..
For AND gates,
\begin{itemize}
\item the first element gives the variable name of the AND gate
(as a positive literal), and
\item the next two elements give the literals whose values are taken
as inputs to the AND gate.
\end{itemize}
For example, the AND gate from Figure \ref{aagCircuit} represented by \verb,6 2 4, is
parsed to \verb.[Var 2, Var 0, Var 1]..

The full AIGER representation for the circuit in Figure \ref{aagCircuit} is
as follows:
\begin{verbatim}
Model { numVars = 3
      , numInputs = 0
      , latches = [ [Var 0, Neg 0, Boolean False]
                  , [Var 1, Var 0, Boolean False] ]
      , outputs = [Var 2]
      , ands = [ [Var 2,Var 0,Var 1] ]
      , bad = []
      , constraints = []}
\end{verbatim}

\section{MiniSat Interface}
\label{impl:minisat}
%Describe the process of implementing the Haskell bindings for Minisat
%functions, including the wrapper functions for Minisat written in C.

The SAT solver for \emph{MC} is MiniSat.
Because the Haskell Foreign Function Interface (FFI) cannot interface with C++ directly,
the interface to the MiniSat SAT solver is composed of a C wrapper for the relevant
MiniSat functions and classes and a Haskell interface to the C wrapper.

In the C wrapper,
every MiniSat class is replaced with a C
type, and every MiniSat function is replaced with a function with an \verb,extern C, function that
calls the MiniSat C++ function. For instance, the following function is
in \verb,Minisat/CSolver.cpp, is a wrapper for the \verb,addClause, in the \verb,Solver,
class:
\begin{lstlisting}[language = C++]
extern "C" int addMinisatClause (Minisat::SimpSolver* solver,
                                 Minisat::vec<Minisat::Lit>* ps) {
  return solver -> addClause (*ps);
}
\end{lstlisting}

The \verb,result, struct to \verb,Minisat/CSolver.h,
allows a single function call to return
all the results of a SAT query. The struct contains an indication of query satisfiability
and pointers to the model and conflict vector (if any) of the \verb,Solver,:
\begin{lstlisting}[language=C]
struct result {
  unsigned solved;
  unsigned modelSize;
  unsigned conflictSize;
  minisatLbool* model;
  litptr* conflict;
} res = {0, 0, 0, 0, 0};
\end{lstlisting}

The function \verb,solveWithAssumps,, a wrapper for the version of \verb,solve(),
that takes an assumption vector as an argument, returns a pointer to a
\verb,result, struct rather than just whether or not the query was satisfiable.
The Haskell interface uses the Haskell FFI and the \verb,hsc2hs, preprocessor
for handling the \verb,result, struct.

Using just the Haskell FFI for calling the C functions does not provide a
sufficient abstraction for use by the rest of the model checker. All
calls to C functions must occur inside of \verb,IO, monads, but having
the interface functions return \verb,IO, monads means that any functions
that use the interface functions to get values from MiniSat would need to
perform all their computations inside monads as well, requiring them to
be written imperatively.
I wrote further functions to allow for a more natural interface to MiniSat,
making use of \verb,unsafePerformIO, to have the functions return
values outside the \verb,IO, monad.

Many of the functions and datatypes in the interface are analogous to functions and structs in
the C wrapper and C++ implementation of MiniSat. For example, the \verb,Solver, datatype is an
analogue to the MiniSat \verb,Solver, object, and itself contains a pointer to an instance of
a MiniSat \verb,Solver, object. Similarly, functions such as \verb,solveWithAssumps, work
analogously to the C wrapper's \verb,solveWithAssumps,, returning a \verb,Result, that contains
whether or not the query was satisfiable and the model or conflict vector (if any).

The information kept in a \verb,Result, is taken directly from the \verb,result, returned by
the C Wrapper functions. I used the \verb,hsc2hs, preprocessor to help handle pointer offsets
when unmarshalling from the C struct. Beyond straightforward unmarshalling, some additional work
to convert from the MiniSat representation of literals to the \emph{MC} representation of
literals was necessary.

I chose to represent a variable with name $x$ taken from the nonnegative integers with
the MiniSat variable $2 \times x$ and its corresponding next-state variable $x'$
with MiniSat variable $(2 \times x) + 1$. The model returned in the \verb,result, struct
points to an array of three-valued boolean (the normal boolean values including an
\emph{undefined} value) \verb,lbool, values indexed by MiniSat variable indices.
To extract models, the array values are accessed, and for each \emph{True} or \emph{False}
value the corresponding positive or negative literal for that index is added to the
\verb,Lit, list representing the model.

\section{Hardware Representation}
\label{impl:representation}
This section describes the representation and construction of hardware models (i.e.
transition systems) and frames in \emph{MC}.
\subsection{Harware Model Representation}
\subsubsection{Literals and Clauses}
The \verb,Lit, data structure in \verb,Model.Model, represents literals in
the model checker.
The \verb,Var, constructor gives positive current-state (unprimed) literals, the \verb,Neg,
constructor gives negative current-state literals, and the \verb,Var', and \verb,Neg', constructors
respectively give positive and negative next-state (primed) literals.
A clause is represented with type \verb,Clause,, where each \verb,Clause, is a
list of the \verb,Lit,s in the clause.

\subsubsection{Transition Systems and Safety Properties}
% Describe how transition systems and safety properties are represented.
The representation of transition systems and the safety property for the model checker to check
are both encompassed in the \verb,Model, data structure in \verb,Model.Model,, which serves
as the representation of the hardware in the model checker:
\begin{lstlisting}
data Model = Model { vars :: Word
                   , initial :: [Clause]
                   , transition :: [Clause]
                   , safe :: Lit } deriving Show
\end{lstlisting}

The inputs $i$ and state variables $x$ in the transition system $T(i,x,I,T)$
are not distinguished, and the total count of variables is kept in \verb,vars,.
Clauses that specify the initial state $I$ are kept in \verb,initial,.
The \verb,transition, list of clauses that specify latches and clauses that specify AND
gates capture the transition relation $T$.
The literal that gives the safety property is given by \verb,safe,.

\subsection{Hardware Model Construction}
% Describe how transition systems are constructed given AIG models.

The \verb,Model.Model, module contains functions to convert the \verb,Model, data
structure from the \verb,Parser.AigModel, module into the hardware model representation used by
the model checker. In particular, the \verb,toModel, function takes a \verb,Parser.AigModel.Model,
and outputs a \verb,Model.Model.Model,. As mentioned before, the \verb,Model.Model.Lit,
data structure only has constructors for variables and their negations; \verb,Lit,s from
the \verb,Parser.AigModel, module are either converted to \verb,Model.Model.Lit,s or, in the case
that they use the \verb,Boolean, constructor, are removed from the model during the conversion of
the \verb,Latch, and \verb,And, components to \verb,Clause,s in \verb,Model.Model, because
Boolean values are not used in these representations.

\subsubsection{Latches}
The \verb,makeLatches, function generates a pair of \verb,Clause, lists
for a list of \verb,Parser.AigModel.Latch,es. The first list contains
clauses whose conjunction describes the latches' initial values,
and the second contains a clauses whose conjunction describes the
latches' next-state values.

Consider a given \verb,Parser.AigModel.Latch, $[l, n, i]$. representing the latch with
output variable $l$, next-state $n$ taken from the set of literals,
and initial value $i$
also taken from the set literals. The \verb,makeLatches, function uses the
values of $l$, $n$, and $i$ to generate \verb,Clause,s that describe the latches' initial values and
next-state values.

Generating the initial value clause of the latch proceeds as follows: if $i = {\it True}$,
then the singleton clause $\{l\}$ is generated for the initial value list, and if $i = {\it False}$,
then the singleton clause $\{\neg l\}$ is generated.
If $i$ is a literal rather than a Boolean value, then the latch is
uninitialized and no clauses are generated for its initial value.

Generating next-state clauses proceeds similarly.
By the semantics of a latch, the clauses generated for the next state should have
a conjunction logically equivalent to $n \Leftrightarrow l'$.
If $n = {\it True}$, then the singleton clause
$\{l'\}$ is generated because the next-state value for the variable is a constant-{\it True} value,
and if $n = {\it False}$, then the singleton clause $\{\neg l'\}$ is generated.
Otherwise, if $n$ is not a Boolean value,
the next-value clauses generated for $l$, are $\{l', \neg n\}$
and $\{\neg l, n\}$. The conjunction of these clauses are, as needed, logically equivalent
to $n \Leftrightarrow l'$, i.e., where $\simeq$ denotes logical equivalence,
%the following hold:
%\begin{align*}
%l' \Leftrightarrow n &\simeq (l' \Rightarrow n) \wedge (n \Rightarrow l')\\
%l' \Rightarrow n &\simeq \neg l' \vee n\\
%n \Rightarrow l' &\simeq l' \vee \neg n.
%\end{align*}
%It follows that the original double implication is equivalent to the 
%the CNF formula that corresponds to the generated clauses:
$$l' \Leftrightarrow n \simeq (\neg l' \vee n) \wedge (l' \vee \neg n).$$

\subsubsection{AND gates}
The \verb,makeAnds, function generates a single \verb,Clause, list for a list of \verb,Parser.AigModel.And,s,
where the conjunction of the clauses in the list describes the relationship between the AND-gate output
and the AND-gate inputs.

Consider a \verb,Parser.AigModel.And,, of the form $[a, i_1, i_2]$, representing the AND gate
with output variable $a$, and inputs $i_1$ and $i_2$.
The \verb,makeAnds, function uses the values of $a$, $i_1$, and $i_2$ to generate the appropriate
\verb,Clause,s that describe the AND gates' values.
By the semantics of AND gates, the current-state clauses generated should have a conjunction
logically equivalent to $a \Leftrightarrow i_1 \wedge i_2$ and the next-state
clauses generated should have a conjunction logically equivalent to
$a' \Leftrightarrow i_1' \wedge i_2'$. The next-state clauses are generated
by priming the generated current-state clauses, so they satisfy
$a' \Leftrightarrow i_1' \wedge i_2'$.

If both $i_1$ and $i_2$ are Booleans (corresponding to both \verb,in1, and \verb,in2, using the \verb,Boolean,
constructor for \verb,Parser.AigModel.Lit,s), then a singleton clause suffices to describe the AND gate.
If $i_1 \wedge i_2$ holds, then the singleton clause $\{a\}$ describes the constantly {\it True} AND gate,
and if not, then the singleton clause $\{\neg a\}$ describes the constantly {\it False} AND gate.

If only one of the inputs ($i_1$ and $i_2$) is a Boolean, then the clauses equivalent to $a \Leftrightarrow i$
are generated, where $i$ is the input that is not a Boolean value and the clauses to generate for $a \Leftrightarrow i$ 
are described in the explanation for generating clauses for latches.

If neither of $i_1$ or $i_2$ are Booleans, then the clauses generated are
$\{\neg a, i_1\}$, $\{\neg a, i_1\}$, and
$\{\neg i_1,\neg i_2, a\}$. The conjunction of these clauses are, as needed,
logically equivalent to $a \Leftrightarrow i_1 \wedge i_2$:
%\begin{align*}
%a \Leftrightarrow (i_1 \wedge i_2) &\simeq (a \Rightarrow i_1 \wedge i_2) \wedge (i_1 \wedge i_2 \Rightarrow a)\\
%a \Rightarrow (i_1 \wedge i_2) &\simeq \neg a \vee (i_1 \wedge i_2)\\
%(i_1 \wedge i_2) \Rightarrow a &\simeq \neg (i_1 \wedge i_2) \vee a
%\end{align*}
%Distributing $\vee$ over $\wedge$ gives further equivalence
%$$\neg a \vee (i_1 \wedge i_2) \simeq
%(\neg a \vee i_1) \wedge (\neg a \vee i_2),$$
%and using de Morgan's laws gives equivalence
%$$\neg (i_1 \wedge i_2) \vee a \simeq
%\neg i_1 \vee \neg i_2 \vee a.$$

%It follows from distribution and application of de Morgan's laws
%that the original double implication is equivalent to the CNF
%formula corresponding to the generated clauses:
$$a \Leftrightarrow i_1 \wedge i_2 \simeq
(\neg a \vee i_1) \wedge (\neg a \vee i_2) \wedge (\neg i_1 \vee \neg i_2 \vee a).$$

\subsection{Frames}
In addition to a representation of transition systems, \emph{MC} needs a representation
of the frames used by the IC3 algorithm.
The \verb,Frame, data structure represents frames in all implementations of \emph{MC}.
Along with the set of clauses (represented by a list of literals), a \verb,Frame, also
includes a \verb,Solver,, which contains at least all the clauses in the frame's set
of clauses.
The \verb,Solver, may also contain the \verb,transition, clauses for the hardware model.

\section{Model Checking}
\label{impl:modelchecker}

I have implemented several variants of the IC3 algorithm:
the most basic variant (\emph{Basic}), a variant that
improves upon \emph{Basic} by discovering smaller CTIs (\emph{BetterCTI}),
and a variant that improves upon \emph{BetterCTI} by considering subsumed clauses
(\emph{BetterPropagation}).

I have also implemented a variation of IC3 that uses priority queues (\emph{PriorityQueue}) and a
variation that uses CTGs to improve generalization (\emph{CTG}).

I describe the overall structure shared by all the variants except the
\emph{PriorityQueue} implementation, and then describe the implementation
details of smaller components of the algorithm and how they differ across
variants. A separate description of the \emph{PriorityQueue} implementation
follows.

\subsection{Overall structure}

The general structure of the algorithm in the implementations is similar
to the structure given in Figure \ref{overview}; however, there are
small differences that result from implementing the algorithm in a
functional language and an adjustment to how the propagation phase is
carried out.

To explain the modifications to the structure of the algorithm,
I give pseudocode in Figure \ref{recstr}
that outlines the general structure shared by all the
implementations of the model checker except {\it PriorityQueue}
and compare this structure with Figure \ref{overview} (see Section
\ref{pqueue} for \emph{PriorityQueue}).

The main components of the algorithm in Figure \ref{recstr} are as follows:
\begin{itemize}
\item The {\it prove} component (line \ref{recstr:prove})
takes a model $M$ and a property $P$ as input
 and provides the same output as the \emph{prove} component in Figure \ref{overview}
\item The ${\it prove'}$ component (line \ref{recstr:prove'})
takes a model $M$, a property $P$,
the frontier frame $F_k$, and the rest of the frames $[F_0,\ldots,F_k]$ as input. It
implements the main loop in Figure \ref{overview}, achieving the looping behavior with
recursive calls (lines \ref{recstr:recursion}, \ref{recstr:mutrecursion}).
\item The {\it pushFrame} component (line \ref{recstr:pushFrame}) takes the old frontier frame
$F_{k - 1}$ to push clauses from, the new frontier frame $F_k$ to push clauses to,
the model $M$, and the rest of the frames $[F_0, \ldots, F_k]$ as input.
It implements a specialized part of the propagation phase.
\item The {\it nextCTI} component (line \ref{recstr:nextCTI})
takes a failing consecution query as input and returns
a CTI, just as in Figure \ref{overview}
\item The {\it proveNegCTI} component (line \ref{recstr:proveNegCTI})
takes a model $M$, a CTI, and a depth $k - 1$ as input and
returns a triple $({\it result}, [G_0, \ldots, G_{k - 1}], G_k)$, where {\it result}
is {\it False} iff the while loop containing {\it proveNegCTI} in Figure \ref{overview}
would return {\it False}.
Each $G_i$ gives the value that frame $F_i$ would have after the termination of
that while loop in Figure \ref{overview}.
\item The {\it propagate} component (line \ref{recstr:propagate})
takes the current frames $[G_0, \ldots, G_k]$ as input and
returns a pair $({\it fixed}, [H_0, \ldots, H_{k-1}, H_k])$, where {\it fixed} is {\it True}
iff the propagation phase loop in Figure \ref{overview} would have returned {\it True}.
Each $H_i$ gives the value that the frame $F_i$ would have after the propagation
phase updated it in Figure \ref{overview}. The Haskell implementation of this component
returns a \verb,Maybe [Frame],, where the function returns \verb,Nothing,
when {\it fixed} is {\it True}.
\item The {\it push} component (line \ref{recstr:push})
takes two frames $F$ and $F'$ as input and returns a
pair $({\it fixed}, G')$, where {\it fixed} is {\it True} iff all clauses in $F$ can
be pushed to $F'$ and $G'$ is the updated value of $F'$ after having pushed all possible
clauses from $F$ to $F'$.
\end{itemize}

\SetKwProg{Let}{let }{ in}{end}
\begin{algorithm}[t]
\DontPrintSemicolon
\Fn{prove$(M,P)$}{ \label{recstr:prove}
  \lIf{$\neg (I \Rightarrow P)$}{ \label{recstr:init}
    \Return{False}
  }
  \Return ${\it prove'}(M,P,I,{\rm nil})$ \label{recstr:prove'call}
}
\Fn{${\it prove'}(M,P,F_k,[F_0,\ldots,F_{k - 1}])$ \label{recstr:prove'}}{
  \eIf{$F_k \wedge T \Rightarrow P'$ \label{recstr:consecution}}
  {\Return{{\it pushFrame}$(F_k, \emptyset,M,P,[F_0,\ldots,F_{k - 1}])$} \label{recstr:pushFrameCall}}
  {\Let{{\it cti} = {\it nextCTI}$(F_k \wedge T \Rightarrow P')$ \label{recstr:nextCTI}, \;
  $({\it result}, [G_0,\ldots,G_{k - 1}], G_k)$ = {\it proveNegCTI}$(M,{\rm cti},k - 1)$ \label{recstr:proveNegCTI}} 
  {
  \If{\it result} {
    \Let{$({\it fixed}, [H_0,\ldots,H_{k - 1},H_k]) = {\it propagate}([G_0,\ldots,G_{k - 1},G_k])$}{ \label{recstr:propagate}
    \lIf{\it fixed}{\Return{True}}
    \lElse{\Return{${prove'}(M,P,H_k,[H_0,\ldots,H_{k - 1}])$} \label{recstr:recursion}}}}
  \lElse{\Return{False}}}}
}
\Fn{pushFrame$(F_{k - 1}, F_k,M,[F_0,\ldots,F_{k - 2}])$}{ \label{recstr:pushFrame}
  \Let{$({\it fixed}, G_k) = {\it push}(F_{k - 1}, F_k)$ \label{recstr:push}}{
  \lIf{\it fixed}{\Return{True}}
  \lElse{\Return{${\it prove'}(M, P, G_k, [F_0,\ldots,F_{k - 2},F_{k - 1}])$} \label{recstr:mutrecursion}}}
}
\caption{General structure of the algorithm implementation in Haskell. The transition relation $T$ is acquired
from the model $M$.}
\label{recstr}
\end{algorithm}

Because the implementation of the model checker is in Haskell, the overall
structure of the algorithm has been modified to be recursive rather than iterative.
The {\it prove} function (line \ref{recstr:prove}) makes an initiation query
(line \ref{recstr:init}), and, if it succeeds, calls
{\it prove'} (line \ref{recstr:prove'call}),
which corresponds to a recursive version of the main while loop
in line \ref{main} of Figure \ref{overview}.

Because functions in Haskell are pure, the assumption made in Figure \ref{overview}
that function can could modify the set of (passed-by-reference) frames can no longer be made.
Instead, the updated values of frames are returned explicitly from the function call in
a tuple along with any other values needed from the function call, as seen in
{\it proveNegCTI}, {\it propagate}, and {\it push}.
%For example, {\it proveNegCTI} (line \ref{recstr:proveNegCTI})
%returns not only the result
%indicating whether or not the negated CTI was proven, but also returns the possibly updated
%values for the frontier frame $G_k$ and previous frames $G_0, \ldots, G_{k - 1}$.

In addition to the necessary language-related modifications to the algorithm, I made a
change to how often the full propagation phase is carried out, calling the {\it pushFrame}
function (line \ref{recstr:pushFrame}) instead where appropriate.

%In Figure \ref{overview}, each iteration of the algorithm calls the propagation
%phase (line \ref{forprop} in Figure \ref{overview});
%however, if the consecution query succeeds and a new frontier frame $F_k$
%is added in that iteration, then none of the frames have had any new clauses
%added to them. As a result, the only frame that modified during the propagation phase
%is the frame $F_k$ because all the frames before $F_{k - 1}$ have already had all
%possible clauses pushed forward in previous iterations.
%Similarly, the only way a fixed point would be detected is if $F_{k - 1} = F_k$,
%since all pairs of consecutive frames except $(F_{k - 1}, F_k)$ have been checked for
%equality.

In the case that the consecution query (line \ref{recstr:consec}) succeeds,
considering pairs of frames other
than $(F_{k - 1}, F_k)$, where $F_{k - 1}$ is the old frontier frame and $F_k$ is
the newly-created frontier frame, is unnecessary work.
Since no frames have been updated, there is nothing to push to frames $F_i$ with
$0 \leq i < k$.
The modified algorithm is such that
that when the consecution query succeeds, it calls the ${\it pushFrame}$ function
(line \ref{recstr:pushFrameCall}) that
checks only a single pair of frames (which also makes the recursive call to ${\it prove}$).
When the consecution query fails, the adjusted algorithm, like the original in Figure \ref{overview},
calls the ${\it propagate}$ function (line \ref{recstr:propagate})
to handle the updates to the frames made by ${\it proveNegCTI}$.

%The {\it propagate} function carries out the propagation phase of the algorithm.
%The actual implementation of the ${\it propagate}$ function returns type \verb,Maybe [Frame],,
%but for the sake of discussing the high level structure of the implementation,
%it is assumed here to return a pair of a Boolean value indicating whether a fixed point
%has been found while pushing clauses and a list of the updated frames.

\subsection{Initiation}
%Describe how the step involving the initiation query is implemented.

The initiation query $I \Rightarrow P$ is an implication, but a MiniSat \verb,Solver, can only
solve queries given in CNF (with an optional assumption cube).
As a result, the implementation of query $I \Rightarrow P$ for frame $I$ and
clause $P$ makes use of the fact that
$I \Rightarrow P$ holds iff $\neg P \wedge I$ is unsatisfiable.
The resulting implementation in \verb,IC3.hs, is the following:

\begin{lstlisting}
initiation :: Frame -> Clause -> Bool
initiation f prop =
  not (satisfiable (solveWithAssumps (solver f) (map neg prop)))
\end{lstlisting}

\subsection{Consecution}
%Describe how the step involving the consecution query is implemented.

Similarly to the initiation query, the consecution query must be expressed in CNF.
All variants make use of the fact that
$F_k \wedge T \Rightarrow P'$ holds iff $\neg P' \wedge F_k \wedge T$ is unsatisfiable
to yield the following implementation:
\begin{lstlisting}
consecution :: Frame -> Clause -> Bool
consecution f prop =
  not (satisfiable (solveWithAssumps (solver f) (map (prime.neg) prop)))
\end{lstlisting}

\subsection{Counterexamples to Induction}
%Describe how the implementation discovers counterexamples
%to induction and proves them unreachable.

CTIs are found by the \verb,nextCTI, function, which
uses results from SAT queries to find a full or partial assignment to
the variables in the \verb,Model,.

\subsubsection{Basic}
In the \emph{Basic} implementation, \verb,nextCTI, asks for a model
(i.e. the set of true literals) for the satisfiable query $\neg P' \wedge F_k \wedge T$.
The current-state literals then give a predecessor state (a state from which
a $\neg P$ state can be reached in one step of the transition relation) for $\neg P$,
i.e., the current-state literals give the CTI.
These current-state literals are extracted from the model in the function that
called \verb,nextCTI,.

\subsubsection{Smaller Counterexamples to Induction}
In the all implementations of the algorithm other than {\it Basic},
\verb,nextCTI, again asks for a model $m$
for the satisfiable query $\neg P' \wedge F_k \wedge T$. The only literals in $m$ that
must be included in the CTI are those current-state literals that result in
the unsatisfiability of $m \wedge P' \wedge T$. That is, the current-state literals of any
subcube $q$ of $m$ for which $q \wedge P' \wedge T$ holds is also a valid CTI, with
the state $m$ being in the set represented by $q$.

The conflict vector resulting from querying the SAT solver with $P' \wedge T$ and assumption
cube $m$ contains such a $q$ that has only literals relevant to the conflict. This $q$ is
then returned to the calling function, which, as in the \emph{Basic} implementation, extracts
the current-state literals from $q$ to obtain the CTI.


\subsection{Propagation}

Both the implementation of the {\it pushFrame} function and the implementation of the
{\it propagate} function in Figure \ref{recstr} (lines \ref{recstr:pushFrame},
\ref{recstr:propagate}) and
Figure \ref{pqueuestr} (lines \ref{pqueuestr:pushFrame}, \ref{pqueuestr:propagate})
rely on the implementation of the
{\it push} function, which has two variants described below.

\subsubsection{Basic}
The {\it Basic} and {\it BetterCTI} implementations' \verb,push, function,
when invoked as \verb,push f model f', tries to push all clauses in \verb,Frame, \verb,f,
that are not in \verb,Frame, \verb,f', to \verb,f', and
results in a pair containing a \verb,Bool, indicating whether a fixed point has been reached
(i.e., all clauses could be pushed) and a \verb,Frame, with all the clauses in \verb,f', and all
the clauses in \verb,f, that could be pushed to \verb,f',.
For each clause in \verb,f, that is not in \verb,f',, the \verb,consecution, function is called to
see if the clause is inductive relative to the frame \verb,f,. If it is, then
the clause can be added to \verb,f',, and if it is not, then the
function must have \verb,False, as the first element in the pair it returns.

\subsubsection{Subsumed clauses}
The \emph{Basic} and \emph{BetterCTI} implementations' \verb,push, function avoids unnecessary
consecution queries by only considering clauses in \verb,f, that are not in \verb,f',.
Further consecution queries may be eliminated by removing the clauses in \verb,f,
that are subsumed by other clauses, which is done by all variants other than {\it Basic}
and \emph{BetterCTI}.

A clause $c$ \emph{subsumes} a clause $c'$ if the literals in $c$ are a subset of the literals
in $c'$. In this case, $c \Rightarrow c'$ holds, so $c'$ can be removed from the set of clauses. By
removing subsumed clauses $c'$ from a frame before trying to push clauses, the model
checker can avoid making the consecution queries that arise from attempts to push those clauses.

The versions of \verb,push, that consider subsumed clauses include a call to the function
\verb,removeSubsumed, when acquiring the list of clauses to attempt to push.
The \verb,removeSubsumed, function takes a list of clauses and removes all clauses in the list
that are subsumed by other clauses in the list. The \verb,push, function replaces the frame
\verb,f, with a version of \verb,f, with all the subsumed clauses in the frame removed for
the rest of the function and proceeds as the basic implementation's \verb,push, function does,
returning a triple containing the updated \verb,f, along with the fixed-point \verb,Bool,
and updates \verb,Frame, \verb,f',.

\subsection{Inductive Generalization}
Finding the minimal inductive subclause (MIC) for a clause is in practice inefficient
\cite{griggio14},
and all implemented versions of generalization
(i.e. all the \verb,inductiveGeneralization, function implementations) approximate the MIC with a call to the function
\verb,generalize,.

\subsubsection{Simple}
The simplest approximation for a MIC attempts to drop each literal in turn and checks
that the resulting clause $c$ satisfies formulas $I \Rightarrow c$ and
$F_k \wedge c \wedge T \Rightarrow c'$ as the original clause did. If the resulting clause
satisfies both queries, then the literal can be successfully dropped,
but if not, the literal is added to a list \verb,needed, of necessary literals.
After a parameterizable number of failed attempts at dropping a literal from the clause or after
having attempted dropping all the literals, the
\verb,inductiveGeneralization, function that implements this approximation
returns the clause resulting from appending the remaining
literals in the clause (i.e. the literals that the \verb,generalize, has not tried to drop)
with the literals in \verb,needed,.

\begin{figure}[t]
\centering
\begin{lstlisting}
inductiveGeneralization :: Clause -> Frame -> Frame -> Model -> Word
                        -> Clause
inductiveGeneralization clause f0 fk m = generalize clause f0 fk []
  where
    generalize cs _ _ needed 0 = cs ++ needed
    generalize [] _ _ needed _ = needed
    generalize (c:cs) f0 fk needed k = 
      let res = solveWithAssumps
                  (solver (getFrameWith ((cs ++ needed):clauses fk) m))
                  (map (prime.neg) (cs ++ needed))
        if not (satisfiable res) && initiation f0 cs
          then generalize cs f0 fk needed k
          else generalize cs f0 fk (c:needed) ( k - 1 ) 
\end{lstlisting}
\caption{The {\tt inductiveGeneralization} Haskell function that approximates the {\it mic} algorithm.}
\end{figure}

This corresponds to the algorithm described in Figure \ref{mic}, but where {\it down} simply
checks for the relative inductiveness of the subclause and does not attempt to expand it.

\subsubsection{Minimal Inductive Subclauses and Counterexamples to Generalization}
The more elaborate version of generalization implements the full
(but limited in number of attempts) {\it mic} algorithm with {\it down} modified
to handle CTGs.

\begin{algorithm}[t]
\DontPrintSemicolon
\Fn{down$(cls, i)$}{
  \lIf{$\neg (I \Rightarrow {\it cls})$}{\Return{False}}
  \lIf{$F_i \wedge {\it cls} \wedge T \Rightarrow {\it cls}'$}{\Return{True}}
  {\it ctg}:= model extracted from SAT query $F_i \wedge {\it cls} \wedge T \Rightarrow {\it cls}'$
  \eIf{$I \Rightarrow \neg{\it ctg}$ {\rm and} $F_i \wedge \neg{\it ctg} \wedge T \Rightarrow \neg {\it ctg}'$}
  { $j := 0$ \;
    \lWhile{$F_j \wedge \neg{\it ctg} \wedge T \Rightarrow \neg {\it ctg}$}{$j := j + 1$}
    $generalizedNegCTG := {\it mic}(\neg ctg,j)$\;
    $F_j := F_j \cup \{{\it generalizedNegCTG}\}$\;
    \Return{${\it down(cls,i)}$}
  }
  {$p$ := $F_i \wedge t$ state such that $F_i \wedge t \wedge p \Rightarrow \neg t'$ \;
  {\it cls} := $cls \cap p$\;
  \Return{down(cls,i)}}
}
\caption{The algorithm for the version of {\it down} that handles CTGs.}
\label{mic}
\end{algorithm}

The modified {\it down} algorithm checks, as in the simple approximation for MIC, for the satisfiability of
$I \Rightarrow c$ and $F_k \wedge c \wedge T \Rightarrow c'$, where $c$ is the subclause passed to
the algorithm.
The difference is that {\it down} does not immediately attempt to expand $c$
if $I \Rightarrow c$ is true and $F_k \wedge c \wedge T \Rightarrow c'$ is
not; in this case, the CTG {\it ctg} is acquired by taking the current literals in
the model the SAT solver gives for $\neg c' \wedge c \wedge T \wedge F_k$.

The {\it down} algorithm then finds the deepest frame $F_{j - 1}$ for which $\neg {\it ctg}$ is inductive,
and attempts to generalize $\neg {\it ctg}$ relative to that frame with a recursive call to the
{\it mic} algorithm. The generalization of $\neg {\it ctg}$ can then be added to frame $F_j$,
and {\it down} is called recursively using the updated set of frames.

The implementation of {\it down} is approximate for the aforementioned efficiency
reasons; the Haskell function \verb,down, that implements
the algorithm takes a parameter \verb,r, that limits the number of CTGs that it will handle for
each non-recursive call to the implementation of the approximation of the {\it mic} algorithm.

\subsection{Priority Queue Variant}
\label{pqueue}
Unlike other variants, which use recursive calls that explicitly specify which property
to prove at which depth, the \emph{PriorityQueue} implementation keeps track of what
to prove next with a priority queue of proof obligations.
This variant of the algorithm makes
use of some of the same functions (e.g. \verb,negCTI, and \verb,push,) as the other variants but
differs in its overall structure.
I provide a definition of proof obligations, an
overview of the structure of the implementation for this variation of the algorithm,
and some implementation details about representing proof obligations and the priority queue.

\subsubsection{Proof Obligations}
A \emph{proof obligation} is a pair $(s,i)$ of a state $s$ that is either a set of bad states
or a CTI and a depth $i$. When the model checker encounters a proof obligation
$(s,i)$ as the highest-priority element of the queue, it must prove $\neg s$ holds for all states
reachable in at most $i$ steps of the transition relation to fulfill
$(s, i)$.

\subsubsection{Overall Structure}
\begin{algorithm}[!Ht]
\DontPrintSemicolon
\Fn{prove$(M,P)$}{
  \lIf{$\neg (I \Rightarrow P)$}{
    \Return{False}
  }
  \Let{${\it queue}$ = {\rm queue containing proof obligation} $(\neg P, 1)$}{
  \Return {${\it fulfillObligations}(M,[I],queue)$}}
}
\Fn{fulfillObligations$(M,[F_0,\ldots,F_k],{\it queue}])$}{
  \Let{$((s,i), {\it q}) = {\it dequeue(queue)}$ \label{dequeue}}{
  \lIf{$F_{i - 1} \wedge T \Rightarrow \neg s'$}{\Return{${\it pushFrame(M, [F_0, \dots, F_k], q, (s,i))}$} \label{pqueuestr:pushFrame}}
  }
  \lElse{\Let{${\it cti = nextCTI(F_{i - 1} \wedge T \Rightarrow \neg s')}$}{
      \If{$I \Rightarrow \neg {\it cti}$}{
        \Let{${\it (fixed, [G_0, \ldots, G_k], d) = propagate([F_0 \cup \{\neg cti\}, F_1, \ldots, F_k], {\it \neg cti})}$ \label{pqueuestr:propagate}}{
          \lIf{\it fixed}{\Return{True}}
          \Return{${\it fulfillObligation(M, [G_0 , \ldots, G_k], (generalize(\neg cti, d),d))}$}
        }
      }
      \lElse{\Return{False}}}}
}
%\Fn{pushFrame$([M, F_0,\ldots,F_k], {\it queue}, (s,i))$}{
%  \Let{$({\it fixed}, G_i) = {\it push}(F_{i - 1}, F_i)$}{
%    \lIf{\it fixed}{\Return{True}}
%    \lElse{\Let{$q = {\it enqueue{(s, i+1), queue)}}$}
%      {\Return{${\it fulfillObligations}(M,[F_0,\ldots,F_{i - 1},G_i,F_{i + 1}, \ldots, F_k], q)$}}}}
%}
\caption{General structure of the algorithm implementation in {\it PriorityQueue}.}
\label{pqueuestr}
\end{algorithm}

The variant of the algorithm used in the {\it PriorityQueue} implementation
relies on a priority queue of proof obligations.
When a proof obligation $(s,i)$ is added to the priority queue,
it is assigned a priority higher than any proof obligation in the queue $(t,j)$ with $j > i$,
lower than any proof obligation in the queue $(u,k)$ with $k < i$, and lower
than any proof obligation already in the queue with the same depth (i.e. any
proof obligation in the queue $(v, i)$). I discuss the
way that the implementation achieves this priority ordering later.

Unlike the other variants, in the {\it PriorityQueue} implementation, there is
no distinction between the negation of the safety property $P$ and any other property that needs
to be proved. The priority queue maintains all the information about which properties need to be proven,
and the main recursive {\it fulfillObligations} function attempts to prove whichever property has the highest priority in the queue, i.e. fulfill the proof obligation with the highest priority (this proof obligation
is the one returned by ${\it dequeue(queue)}$ in line \ref{dequeue} of \ref{pqueuestr}).

Whenever a proof obligation $(s,i)$ is fulfilled (at a certain depth $i$) the proof obligation
$(s, i + 1)$ is added to the queue. Enqueueing the new proof obligation is valid
because $s$ states can reach $\neg P$ states in some
number of steps of the transition relation and should therefore
not be reachable in any number of steps of the transition relation from the initial state.

In attempting to fulfill a proof obligation $(s,i)$, {\it fulfillObligations} proceeds
generally in the same way as the other variants: if a consecution query succeeds,
then {\it pushFrame} is called, and if not, a CTI is discovered with the intent to
prove its negation is inductive relative to frame $F_{i - 1}$.

The structure of the {\it pushFrame} function is modified to accomodate priority queues
and the fact that the pair of frames may not be the pair with the greatest possible depth.
The {\it pushFrame} function pushes clauses from frame $F_{i - 1}$ to frame $F_i$ (where
$F_i$ is not necessarily the frontier frame) and checks
for the equality of $F_{i - 1}$ and $F_i$.
The recursive call in {\it pushFrame} is then
$${\it fulfillObligations}(M,[F_0,\ldots,F_{i - 1},G_i,F_{i + 1}, \ldots, F_k], q),$$
where $q = {\it enqueue((s, i+1), queue)}$, the result of enqueueing the proof obligation
for property $s$ at the next depth $i + 1$ in the priority queue {\it queue}.

When a CTI $c$ for proof obligation $(s,i)$ is discovered, the proof obligation $(c,i - 1)$
for proving the negation of the CTI could enqueued before calling
calling {\it fulfillObligations} recursively again,
but the implementation employs a different approach.
This approach keeps the number of
generalization attempts low by generalizing once when the proof obligation
for the CTI is enqueued rather than generalizing each time a proof obligation
is fulfilled.

The approach employed by the {\it PriorityQueue} implementation checks
that $I \Rightarrow \neg c$, adds $\neg c$ to $F_0$, and then uses a modified
version of {\it propagate} to push clauses and check for fixed points up to
depth $j \leq i$, where $j$ is the greatest value that is less than $i$
such that $\neg c$ is inductive relative to $F_{j - 1}$. If a fixed point is
found, then the algorithm can terminate with success. Otherwise, the clause
$\neg c$ is generalized relative to frame $F_{j - 1}$
using the simpler approximation for finding MICs, giving clause
$\neg d \subseteq c$. The proof obligation $(d,j)$ is then enqueued, and
{\it fulfillObligations} calls itself recursively.

\subsubsection{Proof Obligations and Priority Queues}

The {\it PriorityQueue} implementation represents proof obligations $(s,i)$ using the
\verb,Obligation, type, which is triple type \verb.(Int, Int, Clause)..
The \verb,Obligation, triple
\verb.(i,r,c). consists of the the depth \verb,i,, a
rank \verb,r, for deciding the ordering of proof obligations at the same depth within the priority
queue, and the clause \verb,c, representing $\neg s$. The
function implementing {\it fulfillObligations} is named \verb,proveObligations,.

The priority queue is represented by
a \verb,MinQueue, (the minimal element has the highest
priority) of \verb,Obligation,s.

For example, the initial \verb,MinQueue, created after the successful initiation query
is given by \verb.singleton (1, 0, [prop])., which represents the priority queue that
contains only \verb,Obligation, \verb.(1, 0, [prop])., representing the proof obligation
$(\neg P,1)$, where the clause $P$ is the one that \verb,[prop], represents.

\chapter{Evaluation}
\label{eval}

This chapter discusses the evaluation of the model checker implementations.
I describe the solving capabilities of the \emph{MC} variants (Section \ref{eval:solving})
and how the project aim of being able to solve several solve examples has been met,
the output of the model checker (Section \ref{eval:output}), how benchmarks were
taken (Section \ref{eval:benchmarking}. I then compare the variants' performance
with each other (Section \ref{eval:variants}) and with the reference implementation
\emph{IC3ref} (Section \ref{eval:ic3ref}).

To evaluate the implementations, I ran all variants
on fourteen handwritten examples and over one hundred examples taken from
the Hardware Model Checking Competitions spanning four years \cite{hwmcc10, hwmcc11, hwmcc13}.
I chose examples from HWMCC'10 that had relatively short (under 2 second)
solving times for \verb,ic3,'s in the competition.
Examples were also chosen from HWMCC'11 that did not overlap with HWMCC'10 examples.
To avoid having as much overlap between examples as those from HWMCC'10 and HWMCC'11,
I skipped HWMCC'12 and took examples
with relatively short solving times for some of the solvers from HWMCC'13
\cite{hwmcc13}.

If the elapsed time for attempting to solve an example took longer than ten minutes, that
attempt was considered to have timed out. The parameterizable number of failed attempts
at dropping literals in the \verb,inductiveGeneralization, functions was set to
three, and the parameterizable number of CTGs that each generalization attempt
in the {\it CTG} implementation will handle was also set to three, matching the
values for these parameters used by \emph{IC3ref}.

\section{Correctness}
\label{eval:solving}

The \emph{MC} implementations have passed the HUnit tests for parsing AIGER files,
making MiniSat queries, and model checking. The parser tests involve comparing
the output of the two parsers and checking that they match, the MiniSat tests
involve checking that results from MiniSat queries (including model and conflict
vectors), and the model-checking tests involve checking the results for specific
functions in \verb,IC3.hs, such as \verb,consecution,.

The variants could solve all the handwritten examples and fifty of the HWMCC examples within
ten minutes correctly, and some
variants were able to solve additional examples without timing out.
All solutions reported solutions within the time limit agree with those
given by \emph{IC3ref}, providing evidence for the correctness of the solutions given
by \emph{MC}.

The handwritten examples served as the ``small examples'' that the model checker
was meant to correctly solve as part of the aims of the project, with the largest
(in terms of number of variables) of the handwritten examples,
\verb,simple_counters.aig,, having 82 variables, 77 of which are AND gates.
To provide context for the typical number of variables in the small examples,
the following table provies the number of variables in the handwritten examples involving
a two-bit counter (\verb,counters2.aig,), a three-bit counter (\verb,counters3.aig,),
and a four-bit counter (\verb,counters4.aig,):
\begin{center}
\begin{tabular}{|l | l|}
\hline
Example & Number of Variables \\
\hline
{\tt counters2.aig} & 14\\
{\tt counters3.aig} & 45\\
{\tt counters4.aig} & 79\\
\hline
\end{tabular}
\end{center}

For examples solved without timing out,
the largest (in terms of number of variables) unsafe example for which the variants gave a
solution was \verb,bj08goodbakerycyclef7.aig, with 19900 variables,
and the largest safe example for which the variants gave a solution
was \verb,pdtvsar8multip26.aig, with 7174 variables.
%Note that the number of variables in an example is only weakly
%correlated with the amount of time needed to solve the example.
% (simple linear regression gives $r^2$ less than $0.3$).
\section{Empirical Analysis}

\subsection{Output Format}
\label{eval:output}

All model checker implementations print the string \verb,True, if the safety
property holds (i.e. if a bad state is not reachable from the initial state) and
\verb,False, if it does not. The implementations also provide debug output that provides
statistics on solving if a nonzero number of frames was required to solve the example.
In particular, all variants' outputs give the number of frames, the average number of
literals per clause, the number of CTIs found, and the total number of queries made. The {\it CTG} implementation also reports the number of CTGs found. Sample output
for the {\it CTG} implementation on example \verb,counters3.aig,
is given in Figure \ref{sampleoutput}.

\begin{figure}[t]
\centering
\begin{lstlisting}[keywordstyle = \ttfamily, basicstyle = \footnotesize\ttfamily]
Number of frames: 21
Average number of literals/clause (not counting transition relation): 4.394657835488733
Number of ctis: 91
Number of ctgs: 242
Number of queries: 15225
True
\end{lstlisting}
\caption{Sample output for running the {\it CTG} implementation on example {\tt counters3.aig}.}
\label{sampleoutput}
\end{figure}

\subsection{Benchmarking}
\label{eval:benchmarking}
I took performance benchmarks both for the \emph{MC} variants and for two configurations
of \emph{IC3ref}, where the configurations differ in whether CTG-handling is enabled
or not. For each variant, forty benchmarking samples were taken for each example that
the variant could solve within the time limit.

The collected data consists of execution time,
the number of frames needed to solve an example,
the average number of literals per clause, the number of CTIs discovered, the number of SAT-solver queries,
and, for the \emph{CTG} implementation, the number of CTGs discovered. These measurements can be found in
Appendix \ref{benchmarks}.

Out of the 50 HWMCC examples, 47 did not require finding any
CTIs; for these examples, the \emph{Basic}, \emph{BetterCTI}, \emph{BetterPropagation},
and \emph{CTG} implementations give similar results. 

\section{Performance Impact of Variations}
\label{eval:variants}
%Discuss performance comparison of the naive implementation of the
%model checker and the final implementation of the model checker.

Profiling revealed that functions in the \verb,MiniSat.Minisat, module consume the most time
when solving examples, suggesting that the overall performance of the model checker is heavily dependent on
the size and number of SAT-solver queries.
In this section, I will discuss the impact that different
variants of the model checker have on the size and number of SAT-solver queries and performance.

\begin{figure}[t]
\includegraphics[width=16cm]{litspercls.pdf}
\caption{Average literals per clause averaged over the fourteen handwritten examples and fifty Hardware
Model Checking Competition examples.}
\label{eval:lits}
\end{figure}

\begin{figure}[t]
\includegraphics[width=16cm]{handwritten.pdf}
\caption{Benchmark results for the fourteen handwritten examples on a log scale.}
\label{eval:time}
\end{figure}

\begin{figure}[!ht]
\includegraphics[width=16cm]{numqueries.pdf}
\caption{Number of queries for each variant run on the fourteen handwritten examples on a log scale.}
\label{eval:queries}
\end{figure}

\paragraph{Smaller Counterexamples to Induction}{
The \emph{BetterCTI} implementation exhibits consistently
better performance than the \emph{Basic} implementation for examples
that require finding at least one CTI. In such cases,
discovering CTI clauses with fewer literals leads, as expected, to a smaller average number of
literals per clause (as seen in Figure \ref{eval:lits}), which suggests smaller SAT queries.

As mentioned previously, because the \emph{BetterCTI} implementation uses
CTIs that encompass sets of states rather than single states, when a negated CTI is proven at a depth
$k$, several states have been shown to be unreachable within $k$ steps of the transition relation
from the initial state. Dealing with sets of states rather than single CTI states should allow
the \emph{BetterCTI} implementation to deal with fewer CTIs in some cases (because the CTI sets of states
may encompass several CTI states), leading to fewer queries. Benchmark results
agree with these expectations; for examples that require finding more than one CTI, \emph{BetterCTI}
finds fewer CTIs and makes fewer queries. For example, the \emph{Basic} variant finds 59
CTIs and makes 414 queries to solve \verb,shortp0.aig,, but the \emph{BetterCTI} variant only
finds 3 CTIs and makes 49 queries, an order of magnitude difference.

The improvement of finding more general CTIs enabled the \emph{BetterCTI} variant of the implementation
(and all other implementations that include finding smaller CTIs) to
solve six more examples (\verb,counterp0.aig,, \verb,counterp0neg.aig,, \verb,pdtvishuffman7.aig,, 
\verb,pdtvismiim3.aig,, \verb,6s318r.aig,, \verb,srg5ptimo.aig,) than the \emph{Basic} version without
timing out.}

\paragraph{Propagation}{
Removing subsumed clauses also results in better performance for several examples.
While the performance impact that the improvement has is less drastic than the improvement of
\emph{BetterCTI} over \emph{Basic}, the \emph{BetterPropagation} version performs
considerably better
than the \emph{BetterCTI} version on the \verb,counters3.aig, and \verb,counters4.aig, examples in
particular (as seen in Figure \ref{eval:time}), where the adjustments allow the algorithm to prove the safety properties using fewer
queries (as seen in Figure \ref{eval:queries}). Even for examples such as \verb,pdtvismiim3.aig,, where \emph{BetterPropagation} makes more
queries than \emph{BetterCTI}, \emph{BetterPropagation} manages to perform better than \emph{BetterCTI}
because it makes smaller queries.}

\paragraph{Counterexamples to Generalization}{
The \emph{CTG} variation that deals with CTGs performs worse than the \emph{BetterPropagation} version
on examples, even in cases where \emph{CTG} reduces the average number of frames per clause,
most likely because the examples used are too small for the performance benefits of using CTGs to
eliminate more states to overcome the overheads of finding and proving negated CTGs, which require
making additional queries on each call to the \verb,inductiveGeneralization, function.

Similar results can be found
in the performance of \emph{IC3ref} with basic generalization and
improved (CTG-using) generalization on the same examples: for these small examples,
the reference implementation performs better overall with CTG-handling disabled.}

\paragraph{Priority Queues}{
The \emph{PriorityQueue} implementation generally does not perform as well as the
implementations that do not use priority queues (with the exception of \emph{CTG}).
This result disagrees with findings that implementations of the IC3 algorithm that
use priority queues are more efficient than simple recursive implementations
\cite{een11,griggio14}.
There are
two features of the variant in particular that may account for its worse performance: accumulating
CTIs and early generalization.

One of the performance advantages of the \emph{PriorityQueue} implementation is that CTIs do not need
to be rediscovered \cite{een11}: after a proof obligation $(s,i)$ is enqueued, until the algorithm fails or finds a fixed point,
the queue will always contain a proof obligation $(s,j)$ for $j \geq i$. When the proof obligation $(s,i)$
fulfilled at a certain depth $i$, $(s,i + 1)$ is then enqueued, If $s$ is a CTI for proving a property
$p$ at depth $i + 2$ (i.e. proof obligation $(\neg p, i + 2)$), by the time \verb,proveObligations, removes
proof obligation $(\neg p, i + 2)$ from the priority queue, $(s, i+1)$ has already been fulfilled, so the
CTI $s$ would not, after its initial discovery, need to be discovered again.

%As with the handling of CTGs, avoiding the rediscovery of CTIs may result in worse performance for smaller
%examples. Proof obligations that do not need to be fulfilled in order to find the fixed point may
%have to be proven in the \emph{PriorityQueue} implementation: even if $s$ is not a CTI for proving $p$
%at depth $i + 2$, the proof obligation $(s, i+1)$ would still need to be fulfilled before the
%\verb,proveObligations, attempts to fulfill $(\neg p, i + 2)$.

The \emph{PriorityQueue} implementation performs inductive generalization for each CTI only once, though,
when that CTI's first proof obligation is first enqueued. Rediscovering CTIs would allow the CTIs to
be generalized relative to later frames as well, rather than only to the first frame relative to which
the negated CTI is inductive. Not generalizing CTIs relative to later frames may lead to
\emph{PriorityQueue} making larger queries and explain the variant's higher average number of
literals per clause.
}

\section{Reference Implementation}
\label{eval:ic3ref}
%Discuss performance comparison of final implementation with
%IC3 reference implementation, taking into account differences between
%the implementations.

The performance of this project's model checker implementations is, for all except very small examples
(e.g. \verb,simple1.aag,),
worse compared to the average performance of \emph{IC3ref}
(with or without generalization involving CTGs enabled).

The choice of implementation language may account for much of the difference in performance, as the reference
implementation in C++ has more control over memory allocations than the implementations in Haskell, which is
a garbage-collected language. I mention other differences between the implementations that may explain
some of the performance differences below.

\subsubsection{Model Representation}
The reference implementation differs from this project's implementations in representing the hardware model,
which may account for some of the performance differences.

The reference implementation keeps track of which variables are inputs, latches, and AND gates.
Each \verb,Model, maintains both the the primed and current values for inputs and latches and keeps a
table to memoize the values of AND gates.

%The next-state value for an unprimed variable is provided by a call to the \verb,primeVar, function in the
%\verb,Model, class, which returns the stored value for the corresponding primed variable
%if the variable is an input or latch. If the variable is the output of an AND gate, the \verb,Model,
%either returns a precomputed, stored value for that primed variable or calculates the value of the output
%of the AND gate, inserts the value into the AND table, and returns that value.

As mentioned earlier, when the consecution query $F_k \wedge T \Rightarrow P'$ fails, this corresponds
to the CNF query $F_k \wedge T \wedge \neg P'$ being satisfiable, and while a full satisfying assignment
$s$ gives a CTI state, it is better to use a set of states $c \subset s$ as a CTI cube, so that several
CTI states can be eliminated at once.
The \verb,stateOf, function uses the information kept in \verb,Model,s to extract the smaller
cube from the model $s$ giving the satisfying assignment for a failed consecution query directly,
without further SAT-solver queries.
The Haskell implementations instead use several SAT-solver queries to extract the necessary literals
from $s$.

\subsubsection{MiniSat}
The reference implementation is more closely coupled to MiniSat's implementation. Because both the reference
implementation and MiniSat are in C++, the reference implementation can and does call MiniSat functions
and instantiate MiniSat objects, such as \verb,SimpSolver,s directly.
In contrast, the Haskell implementations
must interact with MiniSat through an interface and suffers from associated overheads, such as those from
marshalling data from the data structures returned from the C wrapper for MiniSat into the corresponding
Haskell data structures.

The reference implementation also makes use of empirical results to improve the performance of MiniSat queries.
For example, in the \verb,stateOf, function, which extracts a model from a failed consecution query
(to e.g. find a CTI cube), the set of literals passed to the MiniSat \verb,Solver, are reordered according
to an ordering of that was found to be the best choice empirically \cite{minisat}.

\subsubsection{Overall Structure}

The reference implementation uses a priority queue, but handles proof obligations
differently than the {\it PriorityQueue} implementation does because \emph{IC3ref}
does not attempt to reduce the number of generalization attmpts or prevent
the rediscovery of CTIs.

For a CTI $s$ that prevents the fulfillment
of a proof obligation at depth $i$, the reference implementation enqueues proof
obligation $(s,i - 1)$
and performs generalization relative to the frame $F_{i - 1}$ each time $\neg s$ has been shown
to be inductive relative to frame $F_{i - 1}$. Generalization does not seem
to be as expensive for \emph{IC3ref} as the Haskell implementations, probably as a
result of aforementioned differences.
The reference implementation also does not
enqueue a new proof obligation $(s, i+1)$ each time a proof obligation $(s, i)$ has been
fulfilled as the \emph{PriorityQueue} implementation does,
so CTIs need to be rediscovered. The efficiency of \emph{IC3ref} otherwise compensates
for the performance disadvantage of rediscovering CTIs.
The safety property is maintained and
handled separately from CTIs; its negation is not included as part of a proof obligation
placed in the priority queue.

\chapter{Conclusion}
\label{conc}

This chapter summarizes the work done and goals met for this project.
Following the summary in Section \ref{conc:summary}, I give
suggestions for further extensions to the project in Section \ref{conc:extensions}.

\section{Summary}
\label{conc:summary}

The IC3 algorithm provides a new way to perform SAT-based symbolic model checking of
safety properties of hardware, and the performance of its initial implementation
\verb,ic3, in HWMCC'10 resulted in the development of several variants of
and extensions to the algorithm.

This project aims to implement a basic version of the IC3 algorithm in Haskell with the
necessary parser and SAT-solver interface, with the goal of having the model checker
be able to check small example hardware models. These goals have been achieved.

I described the implementation of the different components required by
the project in Chapter \ref{impl}.
In addition to the basic version of the IC3 algorithm, I implemented several variants of
\emph{MC} (also described in Chapter \ref{impl}).
The implementations of the model checker can model check not only
the fourteen handwritten examples but also models from the
Hardware Model Checking Competitions with thousands of variables.

In chapter \ref{eval}, I evaluated the different model checker variants by comparing their performance on examples from
the Hardware Model Checking Competition.
The \emph{Basic} implementation correctly
solved fourteen small handwritten examples, validated against the reference implementation
of IC3, meeting the project goal of being able to check
small examples.
The benchmark results show that finding smaller CTI clauses
results in a dramatic improvement in performance, with the best-performing implementation
\emph{betterPropagation} finding smaller CTI clauses and removing subsumed clauses from frames,
though none of the variants performs as well as \emph{IC3ref}.

\section{Further Extensions}
\label{conc:extensions}

Instead of the extensions mentioned in the initial project proposal,
I elected to implement other variants of the model checker and examine their
effects on the model checker's performance.
As a result, interfacing with different SAT solvers and implementing lazy
abstraction-refinement remain as future work.

Implementing interfaces with different SAT solvers may allow more examples to be solved efficiently.
Aaron Bradley notes that the performance of the IC3 algorithm is considerably affected
by the behavior of the SAT solver it uses \cite{bradley12}; even if each SAT query takes the same amount of
time, the algorithm's performance may still vary if the SAT solver behaves even slightly differently.
Because the choice of SAT solver may affect which examples can be solved efficiently, allowing the model
checker to use different SAT solvers may increase the number of examples that can be solved.

Abstraction-refinement is a technique used in verification to mitigate the effects
of the state explosion problem. Abstraction removes irrelevant details of the model,
and if the abstraction is found to be too coarse at some point during verification,
refinement can add necessary details of the model back into the abstraction.
Yakir Vizel, Orna Grumberg, and Sharon Shoham introduced a abstraction-refinement
scheme that is compatible with the IC3 algorithm \cite{vizel12}. The implementation
of this modified algorithm achieved significant speedups compared with the
original IC3 algorithm implementation \verb,ic3,, and a variant
of the model checker in Haskell that uses this abstraction-refinement scheme may 
exhibit a similar improvement.
%The modified algorithm uses different
%abstractions for the different approximated sets of states (i.e. frames). Upon

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the bibliography
\addcontentsline{toc}{chapter}{Bibliography}
\bibliography{refs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the appendices
\appendix

\chapter{AIGER Format}
\label{aiger}
This appendix describes the binary version of the old AIGER format by comparison
with the ASCII version and the new version of the AIGER format by
comparison with the old format.

\paragraph{Binary version}{
The binary version of the format assumes that variable indices
occur in increasing order. Since each literal must be defined, this assumption
allows for variable indices to be omitted when defining inputs or latches.
Inputs are not explicitly listed. the input variables are inferred based on
the value of \verb,I,.
Similarly, latches are specified by only listing their next-state literals'
representations.

The binary format also assumes that AND gates occur in order of their
variable indices and that inputs to an AND gate will
have already been defined before that AND gate.
These assumptions allow AND gates to be represented by two differences
that tend to be small in practice.

For an AND gate specified in the old format by \verb,lhs rhs0 rhs1,,
where inputs \verb,rhs0, and \verb,rhs1, have been ordered such that
$\verb,rhs0, \geq \verb,rhs1,$, define
$$\delta_0 = \verb,lhs, - \verb,rhs0,$$
and
$$\delta_1 = \verb,lhs, - \verb,rhs1,$$

The values $\delta_i$ are represented with the following binary
encoding, giving a more compact representation for AND gates than
the ASCII version of the format.
For 7-bit words $w_0, \ldots w_n$ with
$$\delta_i = w_0 + 2^7w_1 + \ldots + 2^{7n}w_n,$$
$\delta_i$ is represented as the sequence of $n + 1$ bytes
$b_0, \ldots, b_n$, where
\begin{itemize}
\item for $0 \leq k < n$, $b_k$ is the byte obtained by setting the most
significant bit to 1 and the rest of the bits to $w_k$, and
\item $b_n$ is the byte obtained by setting the most
significant bit to 0 and the rest of the bits to $w_n$
\end{itemize}}

\paragraph{New version} {
The new AIGER format begins with a header of the form
\begin{verbatim}
V M I L O A B C J F
\end{verbatim}
where \verb,V,, \verb,M,, \verb,I,, \verb,L,, \verb,O,, \verb,A, are as
in the old format, and
\begin{itemize}
\item \verb,B, gives the number of ``bad state'' properties
\item \verb,C, gives the number of invariant constraints
\item \verb,J, gives the number of justice properties
\item \verb,F, gives the number of fairness constraints
\end{itemize}

The ``bad state'' properties allow for the specification of properties for
negated safety properties separately from the outputs; in
the old AIGER format, such properties had to be specified as outputs.
The invariant constraints allow for the specification of properties that
are true at all states up to and including the state where the ``bad state''
is found.
Justice and fairness constraints are not included in the model used by
the model checker and will not be explained further.

Components are specified after the header in the same order that their
counts occur in the header with the exception of AND gates, which
occur at the end of the file. Latches' initial values can also be specified
now with an additional \verb,0, or \verb,1, after the next-state literal's
index. The initial value may also be given as the index of the latch itself,
in which case the latch is considered to be uninitialized.
If the initial value is omitted, the initial value is assumed to be
0, as in the old version of the format.

The header can be truncated
after giving the AND-gate count if all remaining counts are
zero, allowing parsers for the new AIGER format to be
backwards-compatible.

The new version of the format is otherwise
the same as the old format.}

\chapter{Benchmark Results}
\label{benchmarks}

In the following tables, ``Average Literals per Clause'' is abbreviated as
``ALC,'' and ``Standard Deviation'' is abbreviated as ``SD.''

\section{Basic}
\csvreader[longtable=|l|p{3em}|p{3.5em}|l|l|p{4.5em}|p{4em}|,
    table head= \hline Name & Frames & ALC & CTIs & Queries & Mean Time (s) & SD of
Time(s)\\\hline,
    late after line=\\\hline]%
{basic.csv}{name = \name, frames = \frames, litspercls = \litspercls, ctis = \ctis, queries = \queries, time = \time, stdev = \stdev}%
{\name & \frames & \litspercls & \ctis & \queries & \time & \stdev}%

\section{BetterCTI}
\csvreader[longtable=|l|p{3em}|p{3.5em}|l|l|p{4.5em}|p{4em}|,
    table head= \hline Name & Frames & ALC & CTIs & Queries & Mean Time (s) & SD of Time
(s)\\\hline,
    late after line=\\\hline]%
{betterCTI.csv}{name = \name, frames = \frames, litspercls = \litspercls, ctis = \ctis, queries = \queries, time = \time, stdev = \stdev}%
{\name & \frames & \litspercls & \ctis & \queries & \time & \stdev}%

\section{BetterPropagation}
\csvreader[longtable=|l|p{3em}|p{3.5em}|l|l|p{4.5em}|p{4em}|,
    table head= \hline Name & Frames & ALC & CTIs & Queries & Mean Time (s) & SD of Time
(s)\\\hline,
    late after line=\\\hline]%
{betterPropagation.csv}{name = \name, frames = \frames, litspercls = \litspercls, ctis = \ctis, queries = \queries, time = \time, stdev = \stdev}%
{\name & \frames & \litspercls & \ctis & \queries & \time & \stdev}%

\section{PriorityQueue}
\csvreader[longtable=|l|p{3em}|p{3.5em}|l|l|p{4.5em}|p{4em}|,
    table head= \hline Name & Frames & ALC & CTIs & Queries & Mean Time (s) & SD of Time
(s)\\\hline,
    late after line=\\\hline]%
{priorityQueue.csv}{name = \name, frames = \frames, litspercls = \litspercls, ctis = \ctis, queries = \queries, time = \time, stdev = \stdev}%
{\name & \frames & \litspercls & \ctis & \queries & \time & \stdev}%

\section{CTG}
\csvreader[longtable=|l|p{3em}|p{3.5em}|l|l|l|p{4.5em}|p{4em}|,
    table head= \hline Name & Frames & ALC & CTIs & CTGs & Queries & Mean Time (s) & SD of Time (s)\\\hline,
    late after line=\\\hline]%
{ctg.csv}{name = \name, frames = \frames, litspercls = \litspercls, ctis = \ctis, ctgs = \ctgs, queries = \queries, time = \time, stdev = \stdev}%
{\name & \frames & \litspercls & \ctis & \ctgs & \queries & \time & \stdev}%

%\section{Reference Implementation}

\chapter{Project Proposal}

\input{proposal_noheader}

\end{document}

